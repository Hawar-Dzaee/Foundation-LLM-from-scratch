{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 : vocabulary and (train/val split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine this is out entire dataset. \n",
    "raw_text = 'The cat is hungry I went to the store But it was closed So I went to a different store'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](section_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the dataset into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train raw text: The cat is hungry I went to the store But it was closed \n",
      "====================================================================================================\n",
      "Val raw text: So I went to a different store\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.66 # arbitrary ratio\n",
    "split_index = int(len(raw_text) * ratio)\n",
    "train_raw_text = raw_text[:split_index]\n",
    "val_raw_text = raw_text[split_index:]\n",
    "\n",
    "\n",
    "print(f\"Train raw text: {train_raw_text}\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(f\"Val raw text: {val_raw_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make an assumption that each word is a unique token.<br>\n",
    "This is a simplification and not true in the real world.<br>\n",
    "In practice, we would use a more sophisticated tokenization method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in the corpus:\n",
      "--------------------------------------------------\n",
      "But\n",
      "I\n",
      "So\n",
      "The\n",
      "a\n",
      "cat\n",
      "closed\n",
      "different\n",
      "hungry\n",
      "is\n",
      "it\n",
      "store\n",
      "the\n",
      "to\n",
      "was\n",
      "went\n",
      "==================================================\n",
      "vocab_size: 16\n"
     ]
    }
   ],
   "source": [
    "vocab = list(sorted(set(raw_text.split(' '))))\n",
    "\n",
    "print(\"unique words in the corpus:\")\n",
    "print(\"-\"*50)\n",
    "for i in vocab:\n",
    "    print(i)\n",
    "\n",
    "print(\"=\"*50)\n",
    "vocab_size = len(vocab)\n",
    "print(f'vocab_size: {vocab_size}') # You can think of as number of unique words in the corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: (The) is different from (the)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of tokens to ids:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'But': 0,\n",
       " 'I': 1,\n",
       " 'So': 2,\n",
       " 'The': 3,\n",
       " 'a': 4,\n",
       " 'cat': 5,\n",
       " 'closed': 6,\n",
       " 'different': 7,\n",
       " 'hungry': 8,\n",
       " 'is': 9,\n",
       " 'it': 10,\n",
       " 'store': 11,\n",
       " 'the': 12,\n",
       " 'to': 13,\n",
       " 'was': 14,\n",
       " 'went': 15}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_ids = {token: id for id, token in enumerate(vocab)}\n",
    "print(\"Mapping of tokens to ids:\")\n",
    "tokens_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of ids to tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'But',\n",
       " 1: 'I',\n",
       " 2: 'So',\n",
       " 3: 'The',\n",
       " 4: 'a',\n",
       " 5: 'cat',\n",
       " 6: 'closed',\n",
       " 7: 'different',\n",
       " 8: 'hungry',\n",
       " 9: 'is',\n",
       " 10: 'it',\n",
       " 11: 'store',\n",
       " 12: 'the',\n",
       " 13: 'to',\n",
       " 14: 'was',\n",
       " 15: 'went'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_tokens = {id: token for id, token in enumerate(vocab)}\n",
    "print(\"Mapping of ids to tokens:\")\n",
    "ids_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    return [tokens_to_ids[token] for token in text.strip().split(' ')]\n",
    "\n",
    "def decode(ids):\n",
    "    return ' '.join([ids_to_tokens[id] for id in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 9, 8, 1, 15, 13, 12, 11, 0, 10, 14, 6, 2, 1, 15, 13, 4, 7, 11]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 9, 8]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"The cat is hungry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat is hungry'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([3,5,9,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 : Creating  dataset and dataloader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X aka input \n",
    "max_len = 4  # length of the green bracket\n",
    "stride = 3  # jump of the green bracket\n",
    "\n",
    "# y aka output \n",
    "# The red bracket length and jump are the same as the green bracket,\n",
    "# but it is shifted by one token to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : max_len and stride are hyper-parameters and can be tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](section_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,raw_text,max_len=max_len,stride=stride):\n",
    "        self.token_ids = encode(raw_text)\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for i in range(0,len(self.token_ids)-max_len,stride):\n",
    "            input = self.token_ids[i:i+max_len]\n",
    "            output = self.token_ids[i+1:i+max_len+1]\n",
    "            self.X.append(torch.tensor(input))\n",
    "            self.y.append(torch.tensor(output))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 5, 9, 8]), tensor([5, 9, 8, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Data(train_raw_text)\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  1, 15, 13]), tensor([ 1, 15, 13,  4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = Data(val_raw_text)\n",
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batch_size=1,shuffle=False,drop_last=False,num_workers=0)\n",
    "val_dl   = DataLoader(val_ds,batch_size=1,shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,(x,y) in enumerate(train_dl):\n",
    "#   print(f'Batch Number: {i+1}')\n",
    "#   print(f'x :{x}')\n",
    "#   print(f'y :{y}')\n",
    "#   print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,(x,y) in enumerate(val_dl):\n",
    "#   print(f'Batch Number: {i+1}')\n",
    "#   print(f'x :{x}')\n",
    "#   print(f'y :{y}')\n",
    "#   print('--'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 : Token Embedding and Positional Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking single batch, and we know that the batch size is 1. <br>\n",
    "so we are taking a single example from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 5, 9, 8]])\n",
      "tensor([[5, 9, 8, 1]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "  print(x)\n",
    "  print(y)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1  # batch size \n",
    "d_in = 4  # embedding dimension  [input dimension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings:\n",
      "tensor([[[-0.2223,  1.6871,  0.2284,  0.4676],\n",
      "         [ 0.8657,  0.2444, -0.6629,  0.8073],\n",
      "         [ 0.1991,  0.0457,  0.1530, -0.4757],\n",
      "         [ 1.8793, -0.0721,  0.1578, -0.7735]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# Embedding \n",
    "token_emb = nn.Embedding(vocab_size,d_in)\n",
    "token_embedding = token_emb(x)\n",
    "print('Token Embeddings:')\n",
    "print(token_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embeddings:\n",
      "----------------------------------------\n",
      "tensor([[-1.5256, -0.7502, -0.6540, -1.6095],\n",
      "        [-0.1002, -0.6092, -0.9798, -1.6091],\n",
      "        [-0.7121,  0.3037, -0.7773, -0.2515],\n",
      "        [-0.2223,  1.6871,  0.2284,  0.4676]], grad_fn=<EmbeddingBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "context_window = 4 # [max length of the input sequence the model can handle]\n",
    "num_tokens = 4 # this can not be greater than context window\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Positional embedding\n",
    "pos_emb = nn.Embedding(context_window,d_in)\n",
    "positional_embedding = pos_emb(torch.arange(num_tokens))\n",
    "print('Positional Embeddings:')\n",
    "print('--'*20)\n",
    "print(positional_embedding)\n",
    "print('--'*20)\n",
    "print(positional_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding + Positional Embedding\n",
      "----------------------------------------\n",
      "tensor([[[-1.7479,  0.9369, -0.4256, -1.1418],\n",
      "         [ 0.7655, -0.3648, -1.6427, -0.8018],\n",
      "         [-0.5131,  0.3494, -0.6244, -0.7271],\n",
      "         [ 1.6571,  1.6150,  0.3862, -0.3058]]], grad_fn=<AddBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Token embedding + token embedding \n",
    "tok_pos_emb = token_embedding + positional_embedding\n",
    "print('Token Embedding + Positional Embedding')\n",
    "print('--'*20)\n",
    "print(tok_pos_emb)\n",
    "print('--'*20)\n",
    "print(tok_pos_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4 : Pre Transformer Block Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000,  1.2492, -0.5674, -1.5225],\n",
       "         [ 0.0000, -0.4864, -2.1902, -1.0691],\n",
       "         [-0.6841,  0.4659, -0.8325, -0.9695],\n",
       "         [ 2.2094,  0.0000,  0.5149, -0.4078]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = 0.25 # notice that we are not using it, but we are still initializing it(to see how it works)\n",
    "\n",
    "\n",
    "torch.manual_seed(2)\n",
    "\n",
    "pre_trans_dp = nn.Dropout(dropout)\n",
    "pre_transformer_dp_result = pre_trans_dp(tok_pos_emb)\n",
    "pre_transformer_dp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section5 : Transformer Block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "tensor([[[ 0.2096,  1.4551, -0.3562, -1.3084],\n",
      "         [ 1.1463,  0.5509, -1.5349, -0.1624],\n",
      "         [-0.3144,  1.7046, -0.5748, -0.8154],\n",
      "         [ 1.6361, -0.5812, -0.0645, -0.9905]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "layernorm1 = nn.LayerNorm(d_in)\n",
    "print(layernorm1.weight)\n",
    "print(layernorm1.bias)\n",
    "layernorm1 = layernorm1(pre_transformer_dp_result)\n",
    "print(layernorm1)\n",
    "print('--'*20)\n",
    "print(layernorm1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_q\n",
      "torch.Size([4, 4])\n",
      "------------------------------------------------------------\n",
      "W_k\n",
      "torch.Size([4, 4])\n",
      "------------------------------------------------------------\n",
      "W_v\n",
      "torch.Size([4, 4])\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "d_out = 4\n",
    "\n",
    "W_q = nn.Parameter(torch.tensor([\n",
    "    [-0.5, 0.2, 0.7, -0.9],\n",
    "    [0.1, -0.3, 0.8, 0.4],\n",
    "    [-0.7, 0.6, -0.2, 0.9],\n",
    "    [0.3, -0.8, 0.5, -0.1]\n",
    "]))\n",
    "\n",
    "\n",
    "W_k = nn.Parameter(torch.tensor([\n",
    "    [0.3, -0.5, 0.2, 0.7],\n",
    "    [-0.4, 0.1, -0.6, -0.2],\n",
    "    [0.8, -0.3, 0.5, -0.7],\n",
    "    [-0.1, 0.6, -0.9, 0.4]\n",
    "]))\n",
    "\n",
    "W_v = nn.Parameter(torch.tensor([\n",
    "    [0.2, -0.8, 0.3, 0.5],\n",
    "    [-0.7, 0.4, -0.1, -0.6],\n",
    "    [0.9, -0.2, 0.7, -0.3],\n",
    "    [-0.5, 0.1, -0.4, 0.8]\n",
    "]))\n",
    "\n",
    "\n",
    "\n",
    "print('W_q')\n",
    "print(W_q.data.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('W_k')\n",
    "print(W_k.data.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('W_v')\n",
    "print(W_v.data.shape)\n",
    "print('---'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q,K,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      "tensor([[[-0.1025,  0.4384,  0.7278,  0.2037],\n",
      "         [ 0.5076, -0.7271,  1.4690, -2.1765],\n",
      "         [ 0.4854, -0.2668,  0.8509,  0.5290],\n",
      "         [-1.1282,  1.2553,  0.1980, -1.6640]]])\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n",
      "K\n",
      "tensor([[[-0.6733, -0.6375,  0.1684, -0.4184],\n",
      "         [-1.0882, -0.1550, -0.7226,  1.7017],\n",
      "         [-1.1545,  0.0108, -0.6392, -0.4848],\n",
      "         [ 0.7708, -1.4511,  1.5352,  0.9105]]])\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n",
      "V\n",
      "tensor([[[-0.6430,  0.3548,  0.1914, -1.7081],\n",
      "         [-1.4566, -0.4060, -0.7207,  0.5732],\n",
      "         [-1.3657,  0.9668, -0.3410, -1.6598],\n",
      "         [ 1.1713, -1.6276,  0.9000,  0.3938]]])\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Q = layernorm1 @ W_q\n",
    "K = layernorm1 @ W_k\n",
    "V = layernorm1 @ W_v\n",
    "\n",
    "print('Q')\n",
    "print(Q.data)\n",
    "print(Q.data.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('K')\n",
    "print(K.data)\n",
    "print(K.data.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('V')\n",
    "print(V.data)\n",
    "print(V.data.shape)\n",
    "print('---'*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting Q,K,V into multiple heads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "num_heads = 2               # this is a hyper-parameter and can be tuned. \n",
    "head_dim = d_out//num_heads\n",
    "print(head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_multi_head\n",
      "tensor([[[[-0.1025,  0.4384],\n",
      "          [ 0.5076, -0.7271],\n",
      "          [ 0.4854, -0.2668],\n",
      "          [-1.1282,  1.2553]],\n",
      "\n",
      "         [[ 0.7278,  0.2037],\n",
      "          [ 1.4690, -2.1765],\n",
      "          [ 0.8509,  0.5290],\n",
      "          [ 0.1980, -1.6640]]]])\n",
      "torch.Size([1, 2, 4, 2])\n",
      "------------------------------------------------------------\n",
      "K_multi_head\n",
      "tensor([[[[-0.6733, -0.6375],\n",
      "          [-1.0882, -0.1550],\n",
      "          [-1.1545,  0.0108],\n",
      "          [ 0.7708, -1.4511]],\n",
      "\n",
      "         [[ 0.1684, -0.4184],\n",
      "          [-0.7226,  1.7017],\n",
      "          [-0.6392, -0.4848],\n",
      "          [ 1.5352,  0.9105]]]])\n",
      "torch.Size([1, 2, 4, 2])\n",
      "------------------------------------------------------------\n",
      "V_multi_head\n",
      "tensor([[[[-0.6430,  0.3548],\n",
      "          [-1.4566, -0.4060],\n",
      "          [-1.3657,  0.9668],\n",
      "          [ 1.1713, -1.6276]],\n",
      "\n",
      "         [[ 0.1914, -1.7081],\n",
      "          [-0.7207,  0.5732],\n",
      "          [-0.3410, -1.6598],\n",
      "          [ 0.9000,  0.3938]]]])\n",
      "torch.Size([1, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "Q_multi_head  = Q.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "K_multi_head  = K.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "V_multi_head  = V.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "\n",
    "\n",
    "print('Q_multi_head')\n",
    "print(Q_multi_head.data)\n",
    "print(Q_multi_head.data.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print('K_multi_head')\n",
    "print(K_multi_head.data)\n",
    "print(K_multi_head.data.shape)\n",
    "\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print('V_multi_head')\n",
    "print(V_multi_head.data)\n",
    "print(V_multi_head.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_multi_head_transpose\n",
      "tensor([[[[-0.6733, -1.0882, -1.1545,  0.7708],\n",
      "          [-0.6375, -0.1550,  0.0108, -1.4511]],\n",
      "\n",
      "         [[ 0.1684, -0.7226, -0.6392,  1.5352],\n",
      "          [-0.4184,  1.7017, -0.4848,  0.9105]]]])\n",
      "torch.Size([1, 2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "K_multi_head_transpose = K_multi_head.transpose(2,3)\n",
    "\n",
    "print('K_multi_head_transpose')\n",
    "print(K_multi_head_transpose.data)\n",
    "print(K_multi_head_transpose.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2105,  0.0435,  0.1231, -0.7152],\n",
      "          [ 0.1217, -0.4397, -0.5940,  1.4464],\n",
      "          [-0.1567, -0.4868, -0.5633,  0.7614],\n",
      "          [-0.0406,  1.0331,  1.3161, -2.6912]],\n",
      "\n",
      "         [[ 0.0373, -0.1792, -0.5639,  1.3027],\n",
      "          [ 1.1579, -4.7654,  0.1161,  0.2734],\n",
      "          [-0.0780,  0.2853, -0.8003,  1.7879],\n",
      "          [ 0.7295, -2.9747,  0.6801, -1.2111]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "attn_score = Q_multi_head @ K_multi_head_transpose\n",
    "print(attn_score)\n",
    "print(attn_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(num_tokens,num_tokens),diagonal=1)\n",
    "print(mask)\n",
    "print(mask.bool()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2105,    -inf,    -inf,    -inf],\n",
      "          [ 0.1217, -0.4397,    -inf,    -inf],\n",
      "          [-0.1567, -0.4868, -0.5633,    -inf],\n",
      "          [-0.0406,  1.0331,  1.3161, -2.6912]],\n",
      "\n",
      "         [[ 0.0373,    -inf,    -inf,    -inf],\n",
      "          [ 1.1579, -4.7654,    -inf,    -inf],\n",
      "          [-0.0780,  0.2853, -0.8003,    -inf],\n",
      "          [ 0.7295, -2.9747,  0.6801, -1.2111]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_score = attn_score.masked_fill(mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
    "print(attn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5980, 0.4020, 0.0000, 0.0000],\n",
      "          [0.3934, 0.3115, 0.2951, 0.0000],\n",
      "          [0.1695, 0.3621, 0.4424, 0.0260]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9851, 0.0149, 0.0000, 0.0000],\n",
      "          [0.3457, 0.4469, 0.2074, 0.0000],\n",
      "          [0.4363, 0.0318, 0.4213, 0.1106]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weight = torch.softmax(attn_score/K_multi_head.shape[-1]**0.5,dim=-1)\n",
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.3333, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5361, 0.0000, 0.0000],\n",
      "          [0.5245, 0.0000, 0.3935, 0.0000],\n",
      "          [0.2260, 0.4828, 0.0000, 0.0347]],\n",
      "\n",
      "         [[1.3333, 0.0000, 0.0000, 0.0000],\n",
      "          [1.3134, 0.0199, 0.0000, 0.0000],\n",
      "          [0.4609, 0.5959, 0.2766, 0.0000],\n",
      "          [0.5817, 0.0424, 0.0000, 0.1475]]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "\n",
    "attn_dropout = nn.Dropout(dropout)\n",
    "\n",
    "attn_weight = attn_dropout(attn_weight)\n",
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8573,  0.4730],\n",
      "          [-0.7808, -0.2176],\n",
      "          [-0.8746,  0.5665],\n",
      "          [-0.8080, -0.1723]],\n",
      "\n",
      "         [[ 0.2552, -2.2775],\n",
      "          [ 0.2370, -2.2321],\n",
      "          [-0.4355, -0.9047],\n",
      "          [ 0.2135, -0.9113]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "con_vector = attn_weight @ V_multi_head\n",
    "print(con_vector)\n",
    "print(con_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8573,  0.4730,  0.2552, -2.2775],\n",
       "         [-0.7808, -0.2176,  0.2370, -2.2321],\n",
       "         [-0.8746,  0.5665, -0.4355, -0.9047],\n",
       "         [-0.8080, -0.1723,  0.2135, -0.9113]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_vector = con_vector.transpose(1,2).contiguous().view(B,num_tokens,d_out)\n",
    "conv_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000, -0.3000,  0.4000,  0.2000],\n",
      "        [-0.6000,  0.4000, -0.2000, -0.5000],\n",
      "        [ 0.3000, -0.7000,  0.6000, -0.4000],\n",
      "        [-0.2000,  0.5000, -0.4000,  0.3000]])\n",
      "torch.Size([4, 4])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# projection \n",
    "\n",
    "out_proj = nn.Parameter(torch.tensor([\n",
    "    [0.5, -0.3, 0.4, 0.2],\n",
    "    [-0.6, 0.4, -0.2, -0.5], \n",
    "    [0.3, -0.7, 0.6, -0.4],\n",
    "    [-0.2, 0.5, -0.4, 0.3]\n",
    "]))\n",
    "\n",
    "print(out_proj.data)\n",
    "print(out_proj.data.shape)\n",
    "print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1804, -0.8710,  0.6266, -1.1933],\n",
      "         [ 0.2577, -1.1348,  0.7662, -0.8118],\n",
      "         [-0.7269,  0.3415, -0.3626, -0.5554],\n",
      "         [-0.0543, -0.4316,  0.2039, -0.4343]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "out_proj_result = conv_vector @ out_proj.data\n",
    "print(out_proj_result)\n",
    "print(out_proj_result.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2405, -1.1613,  0.0000, -1.5911],\n",
      "         [ 0.0000, -1.5130,  1.0217, -1.0824],\n",
      "         [-0.9692,  0.0000, -0.4834, -0.7405],\n",
      "         [-0.0724, -0.5755,  0.0000, -0.5790]]], grad_fn=<MulBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "dropout1 = nn.Dropout(dropout)\n",
    "after_dropout_1 = dropout1(out_proj_result)\n",
    "print(after_dropout_1)\n",
    "print(after_dropout_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2405,  0.0878, -0.5674, -3.1136],\n",
      "         [ 0.0000, -1.9994, -1.1686, -2.1514],\n",
      "         [-1.6534,  0.4659, -1.3159, -1.7100],\n",
      "         [ 2.1370, -0.5755,  0.5149, -0.9868]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "skip_connection = after_dropout_1 + pre_transformer_dp_result\n",
    "print(skip_connection)\n",
    "print(skip_connection.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayerNorm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "tensor([[[ 0.7791, -0.6339,  1.1482, -1.2934],\n",
      "         [ 0.3992, -1.1360,  1.4358, -0.6990],\n",
      "         [-1.1686,  1.5222,  0.1800, -0.5336],\n",
      "         [ 0.8623, -0.9891,  1.1287, -1.0019]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "layernorm2 = nn.LayerNorm(after_dropout_1.shape[-1])\n",
    "print(layernorm2.weight)\n",
    "print(layernorm2.bias)\n",
    "layernorm2_result = layernorm2(after_dropout_1)\n",
    "\n",
    "print(layernorm2_result)\n",
    "print(layernorm2_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "----------------------------------------\n",
      "torch.Size([8])\n",
      "----------------------------------------\n",
      "tensor([[[ 1.4730, -2.1377,  1.9447, -0.4745, -0.7107,  0.4600,  0.9876,\n",
      "          -1.5424],\n",
      "         [ 1.5517, -2.1287,  1.8280, -0.2362, -0.6976,  0.2032,  1.1914,\n",
      "          -1.8092],\n",
      "         [-1.2369,  0.3666, -0.1504, -1.3269,  0.1201,  0.7292, -0.5768,\n",
      "           0.4632],\n",
      "         [ 1.6635, -2.1453,  1.9207, -0.1851, -0.6510,  0.1833,  1.1798,\n",
      "          -1.6583]]])\n",
      "torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "fc1_weight = nn.Parameter(torch.tensor([\n",
    "    [0.5, -0.3, 0.4, 0.2, 0.1, -0.2, 0.3, -0.1],\n",
    "    [-0.6, 0.4, -0.2, -0.5, 0.2, 0.3, -0.4, 0.5],\n",
    "    [0.3, -0.7, 0.6, -0.4, -0.3, 0.4, 0.2, -0.6],\n",
    "    [-0.2, 0.5, -0.4, 0.3, 0.4, -0.5, 0.1, 0.2]\n",
    "]))\n",
    "\n",
    "fc1_bias  = nn.Parameter(torch.tensor([0.1, -0.2, 0.3, -0.1, 0.2, -0.3, 0.4, -0.2]))\n",
    "\n",
    "\n",
    "print(fc1_weight.data.shape)\n",
    "print('--'*20)\n",
    "\n",
    "print(fc1_bias.data.shape)\n",
    "print('--'*20)\n",
    "\n",
    "fc1_result = (layernorm2_result @ fc1_weight.data) + fc1_bias.data\n",
    "print(fc1_result.data)\n",
    "print(fc1_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3694, -0.0348,  1.8943, -0.1507, -0.1696,  0.3115,  0.8279,\n",
       "          -0.0948],\n",
       "         [ 1.4581, -0.0354,  1.7662, -0.0961, -0.1693,  0.1180,  1.0523,\n",
       "          -0.0637],\n",
       "         [-0.1337,  0.2358, -0.0662, -0.1224,  0.0658,  0.5593, -0.1627,\n",
       "           0.3142],\n",
       "         [ 1.5835, -0.0342,  1.8681, -0.0789, -0.1676,  0.1050,  1.0394,\n",
       "          -0.0806]]], grad_fn=<GeluBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu = nn.GELU()\n",
    "gelu_result = gelu(fc1_result)\n",
    "gelu_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "----------------------------------------\n",
      "torch.Size([4])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fc2_weight = nn.Parameter(torch.tensor([\n",
    "    [0.5, -0.6, 0.3, -0.2],\n",
    "    [-0.3, 0.4, -0.7, 0.5], \n",
    "    [0.4, -0.2, 0.6, -0.4],\n",
    "    [0.2, -0.5, -0.4, 0.3],\n",
    "    [0.1, 0.2, -0.3, 0.4],\n",
    "    [-0.2, 0.3, 0.4, -0.5],\n",
    "    [0.3, -0.4, 0.2, 0.1],\n",
    "    [-0.1, 0.5, -0.6, 0.2]\n",
    "]))\n",
    "\n",
    "\n",
    "print(fc2_weight.data.shape)\n",
    "print('--'*20)\n",
    "\n",
    "fc2_bias  = nn.Parameter(torch.tensor([0.1, -0.2, 0.3, -0.1]))\n",
    "print(fc2_bias.data.shape)\n",
    "print('--'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.7013, -1.6581,  2.3300, -1.3539],\n",
      "         [ 1.8085, -1.8455,  2.2070, -1.1788],\n",
      "         [-0.2740,  0.4521,  0.0870, -0.1724],\n",
      "         [ 1.9156, -1.9561,  2.3000, -1.2365]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "fc2_result = (gelu_result @ fc2_weight.data) + fc2_bias.data\n",
    "print(fc2_result)\n",
    "print(fc2_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -2.2108,  3.1066, -1.8053],\n",
       "         [ 0.0000, -2.4606,  2.9427, -1.5718],\n",
       "         [-0.3654,  0.6028,  0.1160, -0.2298],\n",
       "         [ 2.5542, -0.0000,  3.0667, -1.6486]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "\n",
    "dropout2 = nn.Dropout(dropout)\n",
    "dropout2_result = dropout2(fc2_result)\n",
    "dropout2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Transformer block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  skip connection 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2405, -2.1230,  2.5392, -4.9188],\n",
      "         [ 0.0000, -4.4600,  1.7741, -3.7232],\n",
      "         [-2.0187,  1.0687, -1.1999, -1.9399],\n",
      "         [ 4.6912, -0.5755,  3.5816, -2.6354]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "skip_connection_2 = skip_connection + dropout2_result\n",
    "print(skip_connection_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Transformer Block LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "tensor([[[ 0.3476, -0.3446,  1.3697, -1.3727],\n",
      "         [ 0.6210, -1.1075,  1.3085, -0.8220],\n",
      "         [-0.7978,  1.6744, -0.1421, -0.7346],\n",
      "         [ 1.1466, -0.6162,  0.7752, -1.3056]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "post_transformer_LN = nn.LayerNorm(d_out)\n",
    "print(post_transformer_LN.weight)\n",
    "print(post_transformer_LN.bias)\n",
    "post_transformer_LN_result = post_transformer_LN(skip_connection_2)\n",
    "print(post_transformer_LN_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n"
     ]
    }
   ],
   "source": [
    "head_out = nn.Parameter(torch.tensor([\n",
    "    [0.5, -0.3, 0.4, 0.2, 0.1, -0.2, 0.3, -0.1, 0.4, -0.5, 0.2, 0.3, -0.2, 0.1, -0.3, 0.4],\n",
    "    [-0.6, 0.4, -0.2, -0.5, 0.2, 0.3, -0.4, 0.5, -0.3, 0.2, -0.5, 0.4, 0.3, -0.2, 0.5, -0.4],\n",
    "    [0.3, -0.7, 0.6, -0.4, -0.3, 0.4, 0.2, -0.6, 0.5, -0.2, 0.4, -0.3, 0.2, -0.5, 0.3, -0.1],\n",
    "    [-0.2, 0.5, -0.4, 0.3, 0.4, -0.5, 0.1, 0.2, -0.4, 0.3, -0.2, 0.5, -0.3, 0.4, -0.5, 0.2]\n",
    "]))\n",
    "\n",
    "print(head_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 16])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_logits = post_transformer_LN_result @ head_out\n",
    "head_out_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0660, -1.8873,  1.5789, -0.7179, -0.9942,  1.0613,  0.3788,\n",
       "          -1.3034,  1.4764, -0.9285,  1.0643, -1.1308,  0.5129, -1.1303,\n",
       "           0.8207, -0.1346],\n",
       "         [ 1.5319, -1.9562,  1.5838, -0.0921, -0.8807,  0.4779,  0.8088,\n",
       "          -1.5653,  1.5637, -1.0403,  1.3657, -1.0603,  0.0519, -0.6994,\n",
       "           0.0635,  0.3961],\n",
       "         [-1.2993,  0.6413, -0.4454, -1.1603,  0.0039,  0.9723, -1.0110,\n",
       "           0.8553, -0.5986,  0.5418, -0.9067,  0.1058,  0.8538, -0.6375,\n",
       "           1.4012, -1.1216],\n",
       "         [ 1.4367, -1.7859,  1.5693, -0.1644, -0.7634,  0.5487,  0.6149,\n",
       "          -1.1490,  1.5534, -1.2433,  1.1086, -0.7879,  0.1326, -0.6720,\n",
       "           0.2333,  0.3665]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_logits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1095, 0.0057, 0.1829, 0.0184, 0.0140, 0.1090, 0.0551, 0.0102,\n",
      "          0.1651, 0.0149, 0.1093, 0.0122, 0.0630, 0.0122, 0.0857, 0.0330],\n",
      "         [0.1622, 0.0050, 0.1708, 0.0320, 0.0145, 0.0565, 0.0787, 0.0073,\n",
      "          0.1674, 0.0124, 0.1373, 0.0121, 0.0369, 0.0174, 0.0373, 0.0521],\n",
      "         [0.0133, 0.0925, 0.0312, 0.0153, 0.0489, 0.1287, 0.0177, 0.1145,\n",
      "          0.0268, 0.0837, 0.0197, 0.0541, 0.1144, 0.0257, 0.1977, 0.0159],\n",
      "         [0.1544, 0.0062, 0.1763, 0.0311, 0.0171, 0.0635, 0.0679, 0.0116,\n",
      "          0.1735, 0.0106, 0.1112, 0.0167, 0.0419, 0.0187, 0.0463, 0.0529]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "# we won't be using the following head_out_prob to calculate the loss, since we can use cross entropy loss \n",
    "# calculating softmax is for demonstration purpose only  \n",
    "\n",
    "head_out_prob = F.softmax(head_out_logits,dim=-1)\n",
    "print(head_out_prob)\n",
    "print(head_out_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 16])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 0, 1, 2, 2, 1, 2, 3, 2, 1, 2, 2, 2, 2, 3]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_prob.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_prob.argmax(dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8299, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn(head_out_logits.squeeze(0),y.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End of the forward pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
