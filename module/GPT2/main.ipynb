{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import yaml\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch import nn\n",
    "import wandb\n",
    "\n",
    "from processing_data.dataset import Data,ClassificationDataset\n",
    "from processing_data.dataloader import get_data_loader\n",
    "from embeddings import Embeddings\n",
    "from transformer_block import TransformerBlock\n",
    "from gpt2 import GPT2Model\n",
    "from utils import text_to_tokens,tokens_to_text\n",
    "from loss import cross_entropy,classification_loss\n",
    "from train import Trainer\n",
    "from evaluation import eval\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "with open(\"config.yaml\",\"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "with open(\"generate_text_config.yaml\",\"r\") as f:\n",
    "    generate_text_config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# API Keys \n",
    "# print(load_dotenv()) \n",
    "# os.environ[\"WANDB_API_KEY\"] = os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off scientific notation\n",
    "torch.set_printoptions(sci_mode=False,precision=10) \n",
    "\n",
    "# read the-verdict.txt\n",
    "with open(\"raw_data/the-verdict.txt\",\"r\") as f: \n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dateset = ClassificationDataset(\n",
    "    csv_path='raw_data/sms_spam_collection/train.csv',\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    max_len=None\n",
    ")\n",
    "val_dataset = ClassificationDataset(\n",
    "    csv_path='raw_data/sms_spam_collection/val.csv',\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    max_len=train_dateset.max_len\n",
    ")\n",
    "\n",
    "test_dataset = ClassificationDataset(\n",
    "    csv_path='raw_data/sms_spam_collection/test.csv',\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    max_len=train_dateset.max_len\n",
    ")\n",
    "\n",
    "train_dl = get_data_loader(train_dateset,batch_size=32,shuffle=False,drop_last=True,num_workers=0)\n",
    "val_dl = get_data_loader(val_dataset,batch_size=32,shuffle=False,drop_last=True,num_workers=0)\n",
    "test_dl = get_data_loader(test_dataset,batch_size=32,shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dateset.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "    print(x.shape)\n",
    "    print('-'*100)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_index = int(len(raw_text) * train_ratio)\n",
    "train_text = raw_text[:split_index]\n",
    "val_text = raw_text[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data(\n",
    "    raw_text=train_text,\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    context_length=config[\"context_window\"],\n",
    "    stride=config[\"stride\"]\n",
    ")\n",
    "\n",
    "val_dataset = Data(\n",
    "    raw_text=val_text,\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    context_length=config[\"context_window\"],\n",
    "    stride=config[\"stride\"]\n",
    ")\n",
    "\n",
    "train_dl = get_data_loader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=config[\"shuffle\"],\n",
    "    drop_last=config[\"drop_last\"],\n",
    "    num_workers=config[\"num_workers\"]\n",
    "    )\n",
    "\n",
    "val_dl = get_data_loader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=config[\"shuffle\"],\n",
    "    drop_last=config[\"drop_last\"],\n",
    "    num_workers=config[\"num_workers\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_dl:\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tokens = 0 \n",
    "# for x,y in train_dl:\n",
    "#     train_tokens += x.numel()\n",
    "# print(f\"Train tokens: {train_tokens}\")\n",
    "\n",
    "# val_tokens = 0\n",
    "# for x,y in val_dl:\n",
    "#     val_tokens += x.numel()\n",
    "# print(f\"Val tokens: {val_tokens}\")\n",
    "\n",
    "\n",
    "# print(f'total tokens: {train_tokens + val_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GPT2Model(config)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     logits = model(x)\n",
    "\n",
    "#     print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhawardizayee\u001b[0m (\u001b[33mhawardizayee-unitedhealthcare\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hawardzaee/Desktop/Galaxy/MyLabV2/Foundation-LLM-from-scratch/module/GPT2/wandb/run-20250510_083540-28gk1cn5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models/runs/28gk1cn5' target=\"_blank\">generate text run 2</a></strong> to <a href='https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models' target=\"_blank\">https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models/runs/28gk1cn5' target=\"_blank\">https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models/runs/28gk1cn5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models/runs/28gk1cn5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x16db838c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Foundation_models\",\n",
    "    name=\"generate text run 2\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    loss_fn=cross_entropy,\n",
    "    optimizer=optimizer,\n",
    "    config=config,\n",
    "    device=\"cpu\",\n",
    "    generate_text_config=generate_text_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 08:35:45,411 - INFO - Epoch 1/10\n",
      "2025-05-10 08:36:01,865 - INFO - Generated text: Every single step  . to,,,-- to the.,, to the----.. \n",
      "2025-05-10 08:36:01,866 - INFO - Epoch 2/10\n",
      "2025-05-10 08:36:14,737 - INFO - Generated text: Every single step it  \" \"              \n",
      "2025-05-10 08:36:14,738 - INFO - Epoch 3/10\n",
      "2025-05-10 08:36:28,194 - INFO - Generated text: Every single step, the the-- the, and a the of of, a a,, the, of of\n",
      "2025-05-10 08:36:28,195 - INFO - Epoch 4/10\n",
      "2025-05-10 08:36:39,729 - INFO - Generated text: Every single step--I-- a of a-- a-- had that I-- I-- had he, he a\n",
      "2025-05-10 08:36:39,730 - INFO - Epoch 5/10\n",
      "2025-05-10 08:36:53,495 - INFO - Generated text: Every single step I was, with, and, and, in a, I had that, I. It--\n",
      "2025-05-10 08:36:53,497 - INFO - Epoch 6/10\n",
      "2025-05-10 08:37:05,556 - INFO - Generated text: Every single step I was the fact of my my he said to the picture of Jack, so--and and in\n",
      "2025-05-10 08:37:05,557 - INFO - Epoch 7/10\n",
      "2025-05-10 08:37:16,240 - INFO - Generated text: Every single step, in a a on my of a and it.  \"I--his the house in\n",
      "2025-05-10 08:37:16,242 - INFO - Epoch 8/10\n",
      "2025-05-10 08:37:32,623 - INFO - Generated text: Every single step have been,\" she on a little he. Gisburn--as his pictures--as to Jack\n",
      "2025-05-10 08:37:32,625 - INFO - Epoch 9/10\n",
      "2025-05-10 08:37:43,778 - INFO - Generated text: Every single step have to have never thought- the a for a little, so the me in a and silver of\n",
      "2025-05-10 08:37:43,780 - INFO - Epoch 10/10\n",
      "2025-05-10 08:37:54,941 - INFO - Generated text: Every single step you, the fact, and pushed, as his pictures--so handsome, so charming, so--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([9.173259417215982,\n",
       "  6.708411110772027,\n",
       "  7.218028174506293,\n",
       "  5.732816855112712,\n",
       "  5.1324782901340065,\n",
       "  4.287467188305325,\n",
       "  3.48931352297465,\n",
       "  2.709184832043118,\n",
       "  1.9903310669793024,\n",
       "  1.3930295175976224],\n",
       " [7.716957092285156,\n",
       "  6.730174541473389,\n",
       "  6.650071144104004,\n",
       "  6.523015022277832,\n",
       "  6.319337844848633,\n",
       "  6.170145511627197,\n",
       "  6.186779975891113,\n",
       "  6.300814628601074,\n",
       "  6.316922664642334,\n",
       "  6.408429145812988])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(epochs=10,generate_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[6109, 2060, 2239,  262]])\n",
    "\n",
    "len(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if any(a<0):\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46080"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.seen_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>seen tokens</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train loss</td><td>█▅▆▅▄▄▃▃▂▁</td></tr><tr><td>val loss</td><td>█▄▃▃▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>seen tokens</td><td>46080</td></tr><tr><td>train loss</td><td>2.47127</td></tr><tr><td>val loss</td><td>6.22698</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">with val run</strong> at: <a href='https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models/runs/s57wt4cq' target=\"_blank\">https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models/runs/s57wt4cq</a><br> View project at: <a href='https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models' target=\"_blank\">https://wandb.ai/hawardizayee-unitedhealthcare/Foundation_models</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250510_073359-s57wt4cq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 10:09:34,487 - INFO - Epoch 1/10\n",
      "2025-05-09 10:09:50,766 - INFO - Seen tokens: 4608\n",
      "2025-05-09 10:09:50,768 - INFO - Loss: 9.1835\n",
      "2025-05-09 10:09:50,994 - INFO - Validation Loss: 7.6791\n",
      "2025-05-09 10:09:50,999 - INFO - ==================================================\n",
      "2025-05-09 10:09:50,999 - INFO - Epoch 2/10\n",
      "2025-05-09 10:10:05,240 - INFO - Seen tokens: 9216\n",
      "2025-05-09 10:10:05,242 - INFO - Loss: 6.6920\n",
      "2025-05-09 10:10:05,481 - INFO - Validation Loss: 6.7152\n",
      "2025-05-09 10:10:05,486 - INFO - ==================================================\n",
      "2025-05-09 10:10:05,486 - INFO - Epoch 3/10\n",
      "2025-05-09 10:10:20,518 - INFO - Seen tokens: 13824\n",
      "2025-05-09 10:10:20,520 - INFO - Loss: 6.8425\n",
      "2025-05-09 10:10:20,888 - INFO - Validation Loss: 6.6327\n",
      "2025-05-09 10:10:20,891 - INFO - ==================================================\n",
      "2025-05-09 10:10:20,892 - INFO - Epoch 4/10\n",
      "2025-05-09 10:10:35,090 - INFO - Seen tokens: 18432\n",
      "2025-05-09 10:10:35,093 - INFO - Loss: 5.9034\n",
      "2025-05-09 10:10:35,309 - INFO - Validation Loss: 6.6238\n",
      "2025-05-09 10:10:35,310 - INFO - ==================================================\n",
      "2025-05-09 10:10:35,310 - INFO - Epoch 5/10\n",
      "2025-05-09 10:10:49,719 - INFO - Seen tokens: 23040\n",
      "2025-05-09 10:10:49,721 - INFO - Loss: 5.7705\n",
      "2025-05-09 10:10:49,940 - INFO - Validation Loss: 6.5725\n",
      "2025-05-09 10:10:49,941 - INFO - ==================================================\n",
      "2025-05-09 10:10:49,942 - INFO - Epoch 6/10\n",
      "2025-05-09 10:11:02,630 - INFO - Seen tokens: 27648\n",
      "2025-05-09 10:11:02,633 - INFO - Loss: 5.5570\n",
      "2025-05-09 10:11:02,833 - INFO - Validation Loss: 6.4826\n",
      "2025-05-09 10:11:02,834 - INFO - ==================================================\n",
      "2025-05-09 10:11:02,834 - INFO - Epoch 7/10\n",
      "2025-05-09 10:11:19,153 - INFO - Seen tokens: 32256\n",
      "2025-05-09 10:11:19,155 - INFO - Loss: 5.2974\n",
      "2025-05-09 10:11:19,392 - INFO - Validation Loss: 6.4752\n",
      "2025-05-09 10:11:19,395 - INFO - ==================================================\n",
      "2025-05-09 10:11:19,395 - INFO - Epoch 8/10\n",
      "2025-05-09 10:11:35,674 - INFO - Seen tokens: 36864\n",
      "2025-05-09 10:11:35,678 - INFO - Loss: 4.9331\n",
      "2025-05-09 10:11:35,907 - INFO - Validation Loss: 6.3157\n",
      "2025-05-09 10:11:35,909 - INFO - ==================================================\n",
      "2025-05-09 10:11:35,909 - INFO - Epoch 9/10\n",
      "2025-05-09 10:11:47,673 - INFO - Seen tokens: 41472\n",
      "2025-05-09 10:11:47,675 - INFO - Loss: 4.2409\n",
      "2025-05-09 10:11:47,879 - INFO - Validation Loss: 6.2301\n",
      "2025-05-09 10:11:47,880 - INFO - ==================================================\n",
      "2025-05-09 10:11:47,880 - INFO - Epoch 10/10\n",
      "2025-05-09 10:11:59,226 - INFO - Seen tokens: 46080\n",
      "2025-05-09 10:11:59,228 - INFO - Loss: 3.6324\n",
      "2025-05-09 10:11:59,436 - INFO - Validation Loss: 6.2022\n",
      "2025-05-09 10:11:59,437 - INFO - ==================================================\n"
     ]
    }
   ],
   "source": [
    "traininng_loop(\n",
    "    model,\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    loss_fn = cross_entropy,\n",
    "    optimizer = optimizer,\n",
    "    num_epochs = 10,\n",
    "    device = \"cpu\",\n",
    "    # text_to_generate = \"Every single step\",\n",
    "    look_back = config[\"context_window\"],\n",
    "    num_tokens_to_generate = config[\"num_tokens_to_generate\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▅▅▄▄▃▃▃▂▁</td></tr><tr><td>seen_tokens</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.63237</td></tr><tr><td>seen_tokens</td><td>46080</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">third try</strong> at: <a href='https://wandb.ai/hawardizayee-unitedhealthcare/GPT2/runs/kmvdrw15' target=\"_blank\">https://wandb.ai/hawardizayee-unitedhealthcare/GPT2/runs/kmvdrw15</a><br> View project at: <a href='https://wandb.ai/hawardizayee-unitedhealthcare/GPT2' target=\"_blank\">https://wandb.ai/hawardizayee-unitedhealthcare/GPT2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250509_100927-kmvdrw15/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 19:14:24,002 - INFO - Validation Loss: 6.3376\n"
     ]
    }
   ],
   "source": [
    "eval(\n",
    "    model,\n",
    "    val_loader=val_dl,\n",
    "    loss_fn= cross_entropy,\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
