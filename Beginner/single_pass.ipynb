{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine this is out entire dataset. \n",
    "raw_text = 'The cat is hungry I went to the store But it was closed So I went to a different store'\n",
    "\n",
    "# In this section, we will split the dataset into train and validation sets. \n",
    "# we will tokenize the dataset and create a vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](section_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the dataset into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train raw text: The cat is hungry I went to the store But it was closed \n",
      "====================================================================================================\n",
      "Val raw text: So I went to a different store\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.66\n",
    "split_index = int(len(raw_text) * ratio)\n",
    "train_raw_text = raw_text[:split_index]\n",
    "val_raw_text = raw_text[split_index:]\n",
    "\n",
    "\n",
    "print(f\"Train raw text: {train_raw_text}\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(f\"Val raw text: {val_raw_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make an assumption that each word is a unique token.<br>\n",
    "This is a simplification and not true in the real world.<br>\n",
    "In practice, we would use a more sophisticated tokenization method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in the corpus:\n",
      "--------------------------------------------------\n",
      "But\n",
      "I\n",
      "So\n",
      "The\n",
      "a\n",
      "cat\n",
      "closed\n",
      "different\n",
      "hungry\n",
      "is\n",
      "it\n",
      "store\n",
      "the\n",
      "to\n",
      "was\n",
      "went\n",
      "==================================================\n",
      "vocab_size: 16\n"
     ]
    }
   ],
   "source": [
    "vocab = list(sorted(set(raw_text.split(' '))))\n",
    "\n",
    "print(\"unique words in the corpus:\")\n",
    "print(\"-\"*50)\n",
    "for i in vocab:\n",
    "    print(i)\n",
    "\n",
    "print(\"=\"*50)\n",
    "vocab_size = len(vocab)\n",
    "print(f'vocab_size: {vocab_size}') # You can think of as number of unique words in the corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: (The) is different from (the)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of tokens to ids:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'But': 0,\n",
       " 'I': 1,\n",
       " 'So': 2,\n",
       " 'The': 3,\n",
       " 'a': 4,\n",
       " 'cat': 5,\n",
       " 'closed': 6,\n",
       " 'different': 7,\n",
       " 'hungry': 8,\n",
       " 'is': 9,\n",
       " 'it': 10,\n",
       " 'store': 11,\n",
       " 'the': 12,\n",
       " 'to': 13,\n",
       " 'was': 14,\n",
       " 'went': 15}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_ids = {token: id for id, token in enumerate(vocab)}\n",
    "print(\"Mapping of tokens to ids:\")\n",
    "tokens_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of ids to tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'But',\n",
       " 1: 'I',\n",
       " 2: 'So',\n",
       " 3: 'The',\n",
       " 4: 'a',\n",
       " 5: 'cat',\n",
       " 6: 'closed',\n",
       " 7: 'different',\n",
       " 8: 'hungry',\n",
       " 9: 'is',\n",
       " 10: 'it',\n",
       " 11: 'store',\n",
       " 12: 'the',\n",
       " 13: 'to',\n",
       " 14: 'was',\n",
       " 15: 'went'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_tokens = {id: token for id, token in enumerate(vocab)}\n",
    "print(\"Mapping of ids to tokens:\")\n",
    "ids_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    return [tokens_to_ids[token] for token in text.strip().split(' ')]\n",
    "\n",
    "def decode(ids):\n",
    "    return ' '.join([ids_to_tokens[id] for id in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 9, 8, 1, 15, 13, 12, 11, 0, 10, 14, 6, 2, 1, 15, 13, 4, 7, 11]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 9, 8]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"The cat is hungry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat is hungry'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([3,5,9,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 : Creating  dataset and dataloader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X aka input \n",
    "max_len = 4  # length of the green bracket\n",
    "stride = 3  # jump of the green bracket\n",
    "\n",
    "# y aka output \n",
    "# The red bracket length and jump are the same as the green bracket,\n",
    "# but it is shifted by one token to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : max_len and stride are hyper-parameters and can be tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](section_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,raw_text,max_len=max_len,stride=stride):\n",
    "        self.token_ids = encode(raw_text)\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for i in range(0,len(self.token_ids)-max_len,stride):\n",
    "            input = self.token_ids[i:i+max_len]\n",
    "            output = self.token_ids[i+1:i+max_len+1]\n",
    "            self.X.append(torch.tensor(input))\n",
    "            self.y.append(torch.tensor(output))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 5, 9, 8]), tensor([5, 9, 8, 1]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Data(train_raw_text)\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  1, 15, 13]), tensor([ 1, 15, 13,  4]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = Data(val_raw_text)\n",
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batch_size=1,shuffle=False,drop_last=False,num_workers=0)\n",
    "val_dl   = DataLoader(val_ds,batch_size=1,shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 1\n",
      "x :tensor([[3, 5, 9, 8]])\n",
      "y :tensor([[5, 9, 8, 1]])\n",
      "----------------------------------------\n",
      "Batch Number: 2\n",
      "x :tensor([[ 8,  1, 15, 13]])\n",
      "y :tensor([[ 1, 15, 13, 12]])\n",
      "----------------------------------------\n",
      "Batch Number: 3\n",
      "x :tensor([[13, 12, 11,  0]])\n",
      "y :tensor([[12, 11,  0, 10]])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(train_dl):\n",
    "  print(f'Batch Number: {i+1}')\n",
    "  print(f'x :{x}')\n",
    "  print(f'y :{y}')\n",
    "  print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 1\n",
      "x :tensor([[ 2,  1, 15, 13]])\n",
      "y :tensor([[ 1, 15, 13,  4]])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(val_dl):\n",
    "  print(f'Batch Number: {i+1}')\n",
    "  print(f'x :{x}')\n",
    "  print(f'y :{y}')\n",
    "  print('--'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 : Token Embedding and Positional Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking single batch, and we know that the batch size is 1. <br>\n",
    "so we are taking a single example from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 5, 9, 8]])\n",
      "tensor([[5, 9, 8, 1]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "  print(x)\n",
    "  print(y)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1  # batch size \n",
    "d_in = 4  # embedding dimension  [input dimension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings:\n",
      "tensor([[[-0.2223,  1.6871,  0.2284,  0.4676],\n",
      "         [ 0.8657,  0.2444, -0.6629,  0.8073],\n",
      "         [ 0.1991,  0.0457,  0.1530, -0.4757],\n",
      "         [ 1.8793, -0.0721,  0.1578, -0.7735]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# Embedding \n",
    "token_emb = nn.Embedding(vocab_size,d_in)\n",
    "token_embedding = token_emb(x)\n",
    "print('Token Embeddings:')\n",
    "print(token_embedding)\n",
    "# print('--'*20)\n",
    "# print(token_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embeddings:\n",
      "----------------------------------------\n",
      "tensor([[-1.5256, -0.7502, -0.6540, -1.6095],\n",
      "        [-0.1002, -0.6092, -0.9798, -1.6091],\n",
      "        [-0.7121,  0.3037, -0.7773, -0.2515],\n",
      "        [-0.2223,  1.6871,  0.2284,  0.4676]], grad_fn=<EmbeddingBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "context_window = 4 # [max length of the input sequence the model can handle]\n",
    "num_tokens = 4 # this can not be greater than context window\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Positional embedding\n",
    "pos_emb = nn.Embedding(context_window,d_in)\n",
    "positional_embedding = pos_emb(torch.arange(num_tokens))\n",
    "print('Positional Embeddings:')\n",
    "print('--'*20)\n",
    "print(positional_embedding)\n",
    "print('--'*20)\n",
    "print(positional_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding + Positional Embedding\n",
      "----------------------------------------\n",
      "tensor([[[-1.7479,  0.9369, -0.4256, -1.1418],\n",
      "         [ 0.7655, -0.3648, -1.6427, -0.8018],\n",
      "         [-0.5131,  0.3494, -0.6244, -0.7271],\n",
      "         [ 1.6571,  1.6150,  0.3862, -0.3058]]], grad_fn=<AddBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Token embedding + token embedding \n",
    "tok_pos_emb = token_embedding + positional_embedding\n",
    "print('Token Embedding + Positional Embedding')\n",
    "print('--'*20)\n",
    "print(tok_pos_emb)\n",
    "print('--'*20)\n",
    "print(tok_pos_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Transformer Block Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000,  1.2492, -0.5674, -1.5225],\n",
       "         [ 0.0000, -0.4864, -2.1902, -1.0691],\n",
       "         [-0.6841,  0.4659, -0.8325, -0.9695],\n",
       "         [ 2.2094,  0.0000,  0.5149, -0.4078]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = 0.25 # notice that we are not using it, but we are still initializing it(to see how it works)\n",
    "\n",
    "\n",
    "torch.manual_seed(2)\n",
    "\n",
    "pre_transformer_dp = nn.Dropout(dropout)\n",
    "pre_transformer_dp_result = pre_transformer_dp(tok_pos_emb)\n",
    "pre_transformer_dp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "tensor([[[ 0.2096,  1.4551, -0.3562, -1.3084],\n",
      "         [ 1.1463,  0.5509, -1.5349, -0.1624],\n",
      "         [-0.3144,  1.7046, -0.5748, -0.8154],\n",
      "         [ 1.6361, -0.5812, -0.0645, -0.9905]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "layernorm1 = nn.LayerNorm(d_in)\n",
    "print(layernorm1.weight)\n",
    "print(layernorm1.bias)\n",
    "layernorm1 = layernorm1(pre_transformer_dp_result)\n",
    "print(layernorm1)\n",
    "print('--'*20)\n",
    "print(layernorm1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_q\n",
      "tensor([[ 0.2576, -0.4707,  0.0695,  0.1826],\n",
      "        [-0.2207,  0.2999, -0.0612, -0.1949],\n",
      "        [-0.0969, -0.1029,  0.1387, -0.0365],\n",
      "        [ 0.2347,  0.2544,  0.0247, -0.0450]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([4, 4])\n",
      "------------------------------------------------------------\n",
      "W_k\n",
      "tensor([[ 0.0725, -0.1862, -0.1602, -0.4888],\n",
      "        [-0.0020, -0.3020,  0.0239,  0.3100],\n",
      "        [ 0.4371, -0.0838,  0.2981,  0.1397],\n",
      "        [ 0.1556, -0.2157,  0.2718,  0.4743]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([4, 4])\n",
      "------------------------------------------------------------\n",
      "W_v\n",
      "tensor([[ 0.3300,  0.4391,  0.4906, -0.2634],\n",
      "        [-0.4556, -0.0833, -0.2115,  0.2570],\n",
      "        [-0.4754,  0.2140,  0.3750, -0.2654],\n",
      "        [-0.2412, -0.2324,  0.0059,  0.1471]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "d_out = 4\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "W_q = nn.Linear(d_in,d_out,bias=False)\n",
    "W_k = nn.Linear(d_in,d_out,bias=False)\n",
    "W_v = nn.Linear(d_in,d_out,bias=False)\n",
    "\n",
    "# REMINDER : THE WEIGHT MATRICES ARE TRANSPOSED \n",
    "print('W_q')\n",
    "print(W_q.weight.T)\n",
    "print(W_q.weight.T.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('W_k')\n",
    "print(W_k.weight.T)\n",
    "print(W_k.weight.T.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('W_v')\n",
    "print(W_v.weight.T)\n",
    "print(W_v.weight.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q,K,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      "tensor([[[-0.5397,  0.0415, -0.1562, -0.1734],\n",
      "         [ 0.2844, -0.2578, -0.1709,  0.1653],\n",
      "         [-0.5928,  0.5108, -0.2260, -0.3319],\n",
      "         [ 0.3236, -1.1898,  0.1159,  0.4590]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n",
      "K\n",
      "tensor([[[-0.3470, -0.1664, -0.4605, -0.3217],\n",
      "         [-0.6142, -0.2162, -0.6721, -0.6809],\n",
      "         [-0.4043, -0.2322, -0.3018,  0.2150],\n",
      "         [-0.0625,  0.0899, -0.5645, -1.4586]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n",
      "V\n",
      "tensor([[[-0.1088,  0.1986, -0.3463,  0.2209],\n",
      "         [ 0.8962,  0.1667, -0.1306,  0.2231],\n",
      "         [-0.4104, -0.2135, -0.7352,  0.5536],\n",
      "         [ 1.0743,  0.9831,  0.8956, -0.7089]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "Q = W_q(layernorm1)\n",
    "K = W_k(layernorm1)\n",
    "V = W_v(layernorm1)\n",
    "\n",
    "\n",
    "print(f'Q\\n{Q}')\n",
    "print(Q.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(f'K\\n{K}')\n",
    "print(K.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(f'V\\n{V}')\n",
    "print(V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting Q,K,V into multiple heads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "num_heads = 2 \n",
    "head_dim = d_out//num_heads\n",
    "print(head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.5397,  0.0415],\n",
      "          [ 0.2844, -0.2578],\n",
      "          [-0.5928,  0.5108],\n",
      "          [ 0.3236, -1.1898]],\n",
      "\n",
      "         [[-0.1562, -0.1734],\n",
      "          [-0.1709,  0.1653],\n",
      "          [-0.2260, -0.3319],\n",
      "          [ 0.1159,  0.4590]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n",
      "------------------------------------------------------------\n",
      "tensor([[[[-0.3470, -0.1664],\n",
      "          [-0.6142, -0.2162],\n",
      "          [-0.4043, -0.2322],\n",
      "          [-0.0625,  0.0899]],\n",
      "\n",
      "         [[-0.4605, -0.3217],\n",
      "          [-0.6721, -0.6809],\n",
      "          [-0.3018,  0.2150],\n",
      "          [-0.5645, -1.4586]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n",
      "------------------------------------------------------------\n",
      "tensor([[[[-0.1088,  0.1986],\n",
      "          [ 0.8962,  0.1667],\n",
      "          [-0.4104, -0.2135],\n",
      "          [ 1.0743,  0.9831]],\n",
      "\n",
      "         [[-0.3463,  0.2209],\n",
      "          [-0.1306,  0.2231],\n",
      "          [-0.7352,  0.5536],\n",
      "          [ 0.8956, -0.7089]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "Q_split  = Q.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "K_split  = K.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "V_split  = V.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "\n",
    "\n",
    "print(Q_split)\n",
    "print(Q_split.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(K_split)\n",
    "print(K_split.shape)\n",
    "\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(V_split)\n",
    "print(V_split.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1804,  0.3225,  0.2086,  0.0375],\n",
       "          [-0.0558, -0.1190, -0.0551, -0.0410],\n",
       "          [ 0.1207,  0.2537,  0.1211,  0.0830],\n",
       "          [ 0.0857,  0.0584,  0.1454, -0.1272]],\n",
       "\n",
       "         [[ 0.1277,  0.2230,  0.0099,  0.3410],\n",
       "          [ 0.0255,  0.0023,  0.0871, -0.1446],\n",
       "          [ 0.2109,  0.3779, -0.0031,  0.6117],\n",
       "          [-0.2011, -0.3905,  0.0637, -0.7349]]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_score = Q_split @ K_split.transpose(2,3)\n",
    "attn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(num_tokens,num_tokens),diagonal=1)\n",
    "print(mask)\n",
    "print(mask.bool()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1804,    -inf,    -inf,    -inf],\n",
      "          [-0.0558, -0.1190,    -inf,    -inf],\n",
      "          [ 0.1207,  0.2537,  0.1211,    -inf],\n",
      "          [ 0.0857,  0.0584,  0.1454, -0.1272]],\n",
      "\n",
      "         [[ 0.1277,    -inf,    -inf,    -inf],\n",
      "          [ 0.0255,  0.0023,    -inf,    -inf],\n",
      "          [ 0.2109,  0.3779, -0.0031,    -inf],\n",
      "          [-0.2011, -0.3905,  0.0637, -0.7349]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_score = attn_score.masked_fill(mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
    "print(attn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5112, 0.4888, 0.0000, 0.0000],\n",
      "          [0.3227, 0.3545, 0.3228, 0.0000],\n",
      "          [0.2574, 0.2525, 0.2686, 0.2215]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5041, 0.4959, 0.0000, 0.0000],\n",
      "          [0.3350, 0.3770, 0.2880, 0.0000],\n",
      "          [0.2655, 0.2322, 0.3202, 0.1820]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weight = torch.softmax(attn_score/K_split.shape[-1]**0.5,dim=-1)\n",
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopped here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.3333, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6518, 0.0000, 0.0000],\n",
      "          [0.4303, 0.0000, 0.4304, 0.0000],\n",
      "          [0.3433, 0.3367, 0.0000, 0.2953]],\n",
      "\n",
      "         [[1.3333, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6721, 0.6612, 0.0000, 0.0000],\n",
      "          [0.4467, 0.5027, 0.3840, 0.0000],\n",
      "          [0.3540, 0.3097, 0.0000, 0.2427]]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "\n",
    "attn_dropout = nn.Dropout(dropout)\n",
    "\n",
    "attn_weight = attn_dropout(attn_weight)\n",
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1451,  0.2648],\n",
      "          [ 0.5841,  0.1087],\n",
      "          [-0.2235, -0.0064],\n",
      "          [ 0.5816,  0.4146]],\n",
      "\n",
      "         [[-0.4617,  0.2945],\n",
      "          [-0.3191,  0.2960],\n",
      "          [-0.5026,  0.4234],\n",
      "          [ 0.0543, -0.0248]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "con_vector = attn_weight @ V_split\n",
    "print(con_vector)\n",
    "print(con_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1451,  0.2648, -0.4617,  0.2945],\n",
       "         [ 0.5841,  0.1087, -0.3191,  0.2960],\n",
       "         [-0.2235, -0.0064, -0.5026,  0.4234],\n",
       "         [ 0.5816,  0.4146,  0.0543, -0.0248]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_vector = con_vector.transpose(1,2).contiguous().view(B,num_tokens,d_out)\n",
    "conv_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2576, -0.4707,  0.0695,  0.1826],\n",
      "        [-0.2207,  0.2999, -0.0612, -0.1949],\n",
      "        [-0.0969, -0.1029,  0.1387, -0.0365],\n",
      "        [ 0.2347,  0.2544,  0.0247, -0.0450]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([4, 4])\n",
      "Parameter containing:\n",
      "tensor([ 0.0725, -0.0020,  0.4371,  0.1556], requires_grad=True)\n",
      "----------------------------------------\n",
      "tensor([[[ 0.0905,  0.2681,  0.3540,  0.0811],\n",
      "         [ 0.2994, -0.1363,  0.4341,  0.2394],\n",
      "         [ 0.1644,  0.2607,  0.3627,  0.1153],\n",
      "         [ 0.1197, -0.1633,  0.4591,  0.1802]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# projection \n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "out_proj = nn.Linear(d_out,d_out,bias=True)\n",
    "print(out_proj.weight.T)\n",
    "print(out_proj.weight.T.shape)\n",
    "print(out_proj.bias)\n",
    "print('--'*20)\n",
    "\n",
    "out_proj_result = out_proj(conv_vector)\n",
    "print(out_proj_result)\n",
    "print(out_proj_result.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1207,  0.3575,  0.4720,  0.1081],\n",
      "         [ 0.3992, -0.1817,  0.5788,  0.3192],\n",
      "         [ 0.2192,  0.3475,  0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000,  0.2402]]], grad_fn=<MulBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "dropout1 = nn.Dropout(dropout)\n",
    "after_dropout_1 = dropout1(out_proj_result)\n",
    "print(after_dropout_1)\n",
    "print(after_dropout_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1207,  1.6067, -0.0954, -1.4144],\n",
      "         [ 0.3992, -0.6680, -1.6115, -0.7498],\n",
      "         [-0.4649,  0.8134, -0.8325, -0.9695],\n",
      "         [ 2.2094,  0.0000,  0.5149, -0.1676]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "skip_connection = after_dropout_1 + pre_transformer_dp_result\n",
    "print(skip_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayerNorm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "tensor([[[-0.9245,  0.5971,  1.3328, -1.0054],\n",
      "         [ 0.4266, -1.6329,  1.0633,  0.1430],\n",
      "         [ 0.5209,  1.3834, -0.9521, -0.9521],\n",
      "         [-0.5771, -0.5771, -0.5771,  1.7313]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "layernorm2 = nn.LayerNorm(after_dropout_1.shape[-1])\n",
    "print(layernorm2.weight)\n",
    "print(layernorm2.bias)\n",
    "layernorm2_result = layernorm2(after_dropout_1)\n",
    "\n",
    "print(layernorm2_result)\n",
    "print(layernorm2_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2576, -0.4707,  0.0695,  0.1826,  0.0725, -0.1862, -0.1602, -0.4888],\n",
      "        [-0.2207,  0.2999, -0.0612, -0.1949, -0.0020, -0.3020,  0.0239,  0.3100],\n",
      "        [-0.0969, -0.1029,  0.1387, -0.0365,  0.4371, -0.0838,  0.2981,  0.1397],\n",
      "        [ 0.2347,  0.2544,  0.0247, -0.0450,  0.1556, -0.2157,  0.2718,  0.4743]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "torch.Size([4, 8])\n",
      "Parameter containing:\n",
      "tensor([ 0.3300, -0.4556, -0.4754, -0.2412,  0.4391, -0.0833,  0.2140, -0.2324],\n",
      "       requires_grad=True)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "fc1 = nn.Linear(d_out,d_out*2,bias=True)\n",
    "print(fc1.weight.T)\n",
    "print(fc1.weight.T.shape)\n",
    "print(fc1.bias)\n",
    "print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4051, -0.2342, -0.4162, -0.5297,  0.7970,  0.0137,  0.5004,\n",
      "           0.1139],\n",
      "         [ 0.7308, -1.2190, -0.1948,  0.1097,  0.9602,  0.2104,  0.4623,\n",
      "          -0.7306],\n",
      "         [ 0.0278, -0.4302, -0.6794, -0.3380, -0.0903, -0.3129, -0.3789,\n",
      "          -0.6428],\n",
      "         [ 0.7709,  0.1428, -0.5175, -0.2910,  0.4155, -0.1266,  0.5911,\n",
      "           0.6113]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "fc1_result = fc1(layernorm2_result)\n",
    "print(fc1_result)\n",
    "print(fc1_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1388, -0.0954, -0.1409, -0.1579,  0.6274,  0.0069,  0.3461,\n",
       "           0.0621],\n",
       "         [ 0.5609, -0.1358, -0.0824,  0.0596,  0.7985,  0.1228,  0.3135,\n",
       "          -0.1699],\n",
       "         [ 0.0142, -0.1435, -0.1688, -0.1243, -0.0419, -0.1180, -0.1335,\n",
       "          -0.1672],\n",
       "         [ 0.6011,  0.0795, -0.1565, -0.1122,  0.2747, -0.0569,  0.4272,\n",
       "           0.4460]]], grad_fn=<GeluBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu = nn.GELU()\n",
    "gelu_result = gelu(fc1_result)\n",
    "gelu_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1822,  0.0491,  0.0512, -0.1133],\n",
      "        [-0.1561, -0.0433, -0.0014,  0.0169],\n",
      "        [-0.0685,  0.0981,  0.3091,  0.2108],\n",
      "        [ 0.1659,  0.0174,  0.1100,  0.1922],\n",
      "        [-0.3328,  0.1291, -0.1317, -0.3456],\n",
      "        [ 0.2120, -0.1378, -0.2135,  0.2192],\n",
      "        [-0.0727, -0.0258, -0.0593,  0.0988],\n",
      "        [ 0.1799, -0.0318, -0.1525,  0.3354]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([8, 4])\n",
      "Parameter containing:\n",
      "tensor([ 0.2334, -0.3221, -0.3362, -0.1705], requires_grad=True)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "fc2 = nn.Linear(2*d_out,d_out,bias=True)\n",
    "print(fc2.weight.T)\n",
    "print(fc2.weight.T.shape)\n",
    "print(fc2.bias)\n",
    "print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0149, -0.2722, -0.5181, -0.3768],\n",
      "         [ 0.0792, -0.2122, -0.4501, -0.5173],\n",
      "         [ 0.2178, -0.3143, -0.3369, -0.3147],\n",
      "         [ 0.2682, -0.2952, -0.4835, -0.2075]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "fc2_result = fc2(gelu_result)\n",
    "print(fc2_result)\n",
    "print(fc2_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0199, -0.3630, -0.6909, -0.5024],\n",
       "         [ 0.1056, -0.2829, -0.6002, -0.6898],\n",
       "         [ 0.2905, -0.4191, -0.4493, -0.4196],\n",
       "         [ 0.3576, -0.3936, -0.6447, -0.2766]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "dropout2 = nn.Dropout(dropout)\n",
    "dropout2_result = dropout2(fc2_result)\n",
    "dropout2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Transformer block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  skip connection 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1008,  1.2437, -0.7862, -1.9168],\n",
      "         [ 0.5048, -0.9510, -2.2117, -1.4396],\n",
      "         [-0.1745,  0.3943, -1.2817, -1.3891],\n",
      "         [ 2.5670, -0.3936, -0.1298, -0.4442]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "skip_connection_2 = skip_connection + dropout2_result\n",
    "print(skip_connection_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Transformer Block LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "tensor([[[ 0.3795,  1.3643, -0.3848, -1.3589],\n",
      "         [ 1.5435,  0.0741, -1.1985, -0.4192],\n",
      "         [ 0.5835,  1.3408, -0.8907, -1.0336],\n",
      "         [ 1.7242, -0.6313, -0.4214, -0.6715]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "post_transformer_LN = nn.LayerNorm(d_out)\n",
    "print(post_transformer_LN.weight)\n",
    "print(post_transformer_LN.bias)\n",
    "post_transformer_LN_result = post_transformer_LN(skip_connection_2)\n",
    "print(post_transformer_LN_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2576, -0.4707,  0.0695,  0.1826,  0.0725, -0.1862, -0.1602, -0.4888,\n",
      "          0.3300,  0.4391,  0.4906, -0.2634, -0.1444,  0.2713, -0.0234, -0.3232],\n",
      "        [-0.2207,  0.2999, -0.0612, -0.1949, -0.0020, -0.3020,  0.0239,  0.3100,\n",
      "         -0.4556, -0.0833, -0.2115,  0.2570, -0.0548, -0.1215, -0.3337,  0.3248],\n",
      "        [-0.0969, -0.1029,  0.1387, -0.0365,  0.4371, -0.0838,  0.2981,  0.1397,\n",
      "         -0.4754,  0.2140,  0.3750, -0.2654, -0.4807,  0.4980,  0.3045,  0.3036],\n",
      "        [ 0.2347,  0.2544,  0.0247, -0.0450,  0.1556, -0.2157,  0.2718,  0.4743,\n",
      "         -0.2412, -0.2324,  0.0059,  0.1471, -0.2384,  0.4008,  0.1552,  0.4434]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "torch.Size([4, 16])\n",
      "Parameter containing:\n",
      "tensor([-0.2803, -0.0823, -0.0097,  0.0730, -0.3795, -0.3548,  0.2720, -0.1172,\n",
      "         0.2442,  0.0285,  0.1642,  0.1099,  0.1818,  0.2479, -0.4631,  0.2517],\n",
      "       requires_grad=True)\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[[-0.7652, -0.1579, -0.1537, -0.0483, -0.7343, -0.5121, -0.2401,\n",
      "          -0.5781,  0.2586,  0.3149, -0.0906,  0.2629,  0.5612, -0.5513,\n",
      "          -1.2553, -0.1473],\n",
      "         [ 0.1188, -0.7700, -0.0835,  0.4030, -0.8568, -0.4738, -0.4447,\n",
      "          -1.2149,  1.3907,  0.5410,  0.4539, -0.0212,  0.6309, -0.1072,\n",
      "          -0.9539, -0.7728],\n",
      "         [-0.5821, -0.1262, -0.2002, -0.0027, -0.8900, -0.5708, -0.3358,\n",
      "          -0.6015,  0.4987,  0.2226, -0.1733,  0.3852,  0.6986, -0.6146,\n",
      "          -1.3558, -0.2302],\n",
      "         [ 0.1865, -1.2107,  0.0738,  0.5565, -0.5419, -0.3051, -0.3275,\n",
      "          -1.5330,  1.4632,  0.9040,  0.9817, -0.4934,  0.3301,  0.3134,\n",
      "          -0.5252, -0.9363]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "head_out = nn.Linear(d_out,vocab_size,bias=True)\n",
    "print(head_out.weight.T)\n",
    "print(head_out.weight.T.shape)\n",
    "print(head_out.bias)\n",
    "print('----'*20)\n",
    "\n",
    "head_out_result = head_out(post_transformer_LN_result)\n",
    "print(head_out_result)\n",
    "print(head_out_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0334, 0.0614, 0.0616, 0.0685, 0.0345, 0.0431, 0.0565, 0.0403,\n",
       "          0.0931, 0.0985, 0.0657, 0.0935, 0.1260, 0.0414, 0.0205, 0.0620],\n",
       "         [0.0629, 0.0259, 0.0514, 0.0836, 0.0237, 0.0348, 0.0358, 0.0166,\n",
       "          0.2244, 0.0959, 0.0879, 0.0547, 0.1050, 0.0502, 0.0215, 0.0258],\n",
       "         [0.0391, 0.0616, 0.0572, 0.0697, 0.0287, 0.0395, 0.0500, 0.0383,\n",
       "          0.1151, 0.0873, 0.0588, 0.1028, 0.1406, 0.0378, 0.0180, 0.0555],\n",
       "         [0.0591, 0.0146, 0.0528, 0.0856, 0.0285, 0.0361, 0.0353, 0.0106,\n",
       "          0.2118, 0.1211, 0.1309, 0.0299, 0.0682, 0.0671, 0.0290, 0.0192]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we won't be using the following head_out_prob to calculate the loss, since we can use cross entropy loss \n",
    "# calculating softmax is for demonstration purpose only  \n",
    "\n",
    "head_out_prob = F.softmax(head_out_result,dim=-1)\n",
    "head_out_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 16])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  8, 12,  8]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_result.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9692, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn(head_out_result.squeeze(0),y.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End of the forward pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
