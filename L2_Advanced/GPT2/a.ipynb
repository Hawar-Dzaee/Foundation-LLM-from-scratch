{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from dataset import Data\n",
    "from dataloader import get_data_loader\n",
    "from embeddings import Embeddings\n",
    "from transformer_block import TransformerBlock\n",
    "from gpt2 import GPT2Model\n",
    "from utils import text_to_tokens,tokens_to_text,generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\",\"r\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\",\"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   40,   367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,\n",
      "          257,  7026, 15632,   438,  2016,   257,   922,  5891,  1576,   438,\n",
      "          568,   340,   373,   645,  1049,  5975,   284,   502,   284,  3285,\n",
      "          326,    11,   287,   262,  6001,   286,   465, 13476,    11,   339,\n",
      "          550,  5710,   465, 12036,    11,  6405,   257,  5527, 27075,    11,\n",
      "          290,  4920,  2241,   287,   257,  4489,    64,   319,   262, 34686,\n",
      "        41976,    13,   357, 10915,   314,  2138,  1807,   340,   561,   423,\n",
      "          587, 10598,   393, 28537,  2014,   198,   198,     1,   464,  6001,\n",
      "          286,   465, 13476,     1,   438,  5562,   373,   644,   262,  1466,\n",
      "         1444,   340,    13,   314,   460,  3285,  9074,    13, 46606,   536])\n"
     ]
    }
   ],
   "source": [
    "dataset = Data(\n",
    "    raw_text=raw_text,\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    context_length=config[\"context_window\"],\n",
    "    stride=config[\"stride\"]\n",
    ")\n",
    "\n",
    "x,y = dataset[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dl = get_data_loader(\n",
    "    dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=config[\"shuffle\"],\n",
    "    drop_last=config[\"drop_last\"],\n",
    "    num_workers=config[\"num_workers\"]\n",
    "    )\n",
    "\n",
    "\n",
    "for x,y in data_dl:\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1885,  0.5600,  1.0801,  ...,  0.5421, -0.4958,  0.6919],\n",
       "         [ 0.9804,  0.2871,  0.4639,  ..., -0.2104,  0.0651, -0.2675],\n",
       "         [-1.1312, -0.0660,  0.0617,  ..., -0.5819, -0.2791, -0.8605],\n",
       "         ...,\n",
       "         [-1.0856,  0.5250,  0.9901,  ...,  0.0087, -0.3210,  0.3992],\n",
       "         [-0.5326,  0.5916,  1.0956,  ...,  0.8331, -0.4603,  0.8156],\n",
       "         [-0.6084, -0.4086, -0.4806,  ..., -0.2545, -0.3621, -1.3536]],\n",
       "\n",
       "        [[-0.4239,  0.7177,  1.2581,  ...,  0.4373, -0.2909,  0.8573],\n",
       "         [ 0.5074, -0.0963, -0.0696,  ...,  0.0706, -0.1918, -0.7700],\n",
       "         [-0.4271, -0.3529, -0.4386,  ..., -0.7955, -0.1506, -1.4997],\n",
       "         ...,\n",
       "         [-0.8159, -0.3077, -0.3329,  ..., -0.6441, -0.2570, -1.3272],\n",
       "         [ 0.9792,  0.2994,  0.4826,  ..., -0.2133,  0.0685, -0.2474],\n",
       "         [-0.9457, -0.3531, -0.3584,  ..., -0.0186, -0.4830, -1.1320]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2Model(config)\n",
    "\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 50257])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'every step takes you schemes Explpport'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\n",
    "    \"every step takes you\",\n",
    "    model,\n",
    "    \"cpu\",\n",
    "    look_back=40,\n",
    "    num_tokens_to_generate=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randint(0,10000,(2,3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
