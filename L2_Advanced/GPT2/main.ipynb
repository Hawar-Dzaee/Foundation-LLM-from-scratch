{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from processing_data.dataset import Data,SpamDataset\n",
    "from processing_data.dataloader import get_data_loader\n",
    "from embeddings import Embeddings\n",
    "from transformer_block import TransformerBlock\n",
    "from gpt2 import GPT2Model\n",
    "from utils import text_to_tokens,tokens_to_text,generate_text\n",
    "from loss import cross_entropy,classification_loss\n",
    "from train import traininng_loop\n",
    "from evaluation import eval\n",
    "\n",
    "with open(\"config.yaml\",\"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False,precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"raw_data/the-verdict.txt\",\"r\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "len(text_to_tokens(raw_text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dateset = SpamDataset(\n",
    "    csv_path='raw_data/sms_spam_collection/train.csv',\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    max_len=None\n",
    ")\n",
    "val_dataset = SpamDataset(\n",
    "    csv_path='raw_data/sms_spam_collection/val.csv',\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    max_len=train_dateset.max_len\n",
    ")\n",
    "\n",
    "test_dataset = SpamDataset(\n",
    "    csv_path='raw_data/sms_spam_collection/test.csv',\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    max_len=train_dateset.max_len\n",
    ")\n",
    "\n",
    "train_dl = get_data_loader(train_dateset,batch_size=32,shuffle=False,drop_last=True,num_workers=0)\n",
    "val_dl = get_data_loader(val_dataset,batch_size=32,shuffle=False,drop_last=True,num_workers=0)\n",
    "test_dl = get_data_loader(test_dataset,batch_size=32,shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dateset.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n",
      "torch.Size([32, 118])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "    print(x.shape)\n",
    "    print('-'*100)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_index = int(len(raw_text) * train_ratio)\n",
    "train_text = raw_text[:split_index]\n",
    "val_text = raw_text[split_index:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data(\n",
    "    raw_text=train_text,\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    context_length=config[\"context_window\"],\n",
    "    stride=config[\"stride\"]\n",
    ")\n",
    "\n",
    "val_dataset = Data(\n",
    "    raw_text=val_text,\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\"),\n",
    "    context_length=config[\"context_window\"],\n",
    "    stride=config[\"stride\"]\n",
    ")\n",
    "\n",
    "train_dl = get_data_loader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=config[\"shuffle\"],\n",
    "    drop_last=config[\"drop_last\"],\n",
    "    num_workers=config[\"num_workers\"]\n",
    "    )\n",
    "\n",
    "val_dl = get_data_loader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=config[\"shuffle\"],\n",
    "    drop_last=config[\"drop_last\"],\n",
    "    num_workers=config[\"num_workers\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_dl:\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tokens = 0 \n",
    "# for x,y in train_dl:\n",
    "#     train_tokens += x.numel()\n",
    "# print(f\"Train tokens: {train_tokens}\")\n",
    "\n",
    "# val_tokens = 0\n",
    "# for x,y in val_dl:\n",
    "#     val_tokens += x.numel()\n",
    "# print(f\"Val tokens: {val_tokens}\")\n",
    "\n",
    "\n",
    "# print(f'total tokens: {train_tokens + val_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['num_classes'] = 2\n",
    "\n",
    "model = GPT2Model(config)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     logits = model(x)\n",
    "\n",
    "#     print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6434470415)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_loss(logits,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:34:45,320 - INFO - Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:37:02,559 - INFO - Seen tokens: 120832\n",
      "2025-05-02 18:37:02,560 - INFO - Loss: 1.3120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:37:06,698 - INFO - Validation Loss: 0.7209\n",
      "2025-05-02 18:37:06,699 - INFO - ==================================================\n",
      "2025-05-02 18:37:06,699 - INFO - Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n",
      "check point 7\n",
      "check point 8\n",
      "check point 9\n",
      "check point 1\n",
      "check point 2\n",
      "check point 3\n",
      "check point 4\n",
      "check point 5\n",
      "check point 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtraininng_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# text_to_generate = \"Every single step\",\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlook_back\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext_window\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_tokens_to_generate\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_tokens_to_generate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Galaxy/MyLabV2/Foundation-LLM-from-scratch/L2_Advanced/GPT2/train.py:48\u001b[39m, in \u001b[36mtraininng_loop\u001b[39m\u001b[34m(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, device, text_to_generate, look_back, num_tokens_to_generate)\u001b[39m\n\u001b[32m     46\u001b[39m loss.backward()\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcheck point 6\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcheck point 7\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m train_loss.append(loss.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Galaxy/MyLabV2/Foundation-LLM-from-scratch/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Galaxy/MyLabV2/Foundation-LLM-from-scratch/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Galaxy/MyLabV2/Foundation-LLM-from-scratch/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:243\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    230\u001b[39m     beta1, beta2 = cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    232\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    233\u001b[39m         group,\n\u001b[32m    234\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m         state_steps,\n\u001b[32m    241\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Galaxy/MyLabV2/Foundation-LLM-from-scratch/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Galaxy/MyLabV2/Foundation-LLM-from-scratch/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:875\u001b[39m, in \u001b[36madamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    873\u001b[39m     func = _single_tensor_adamw\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Galaxy/MyLabV2/Foundation-LLM-from-scratch/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:425\u001b[39m, in \u001b[36m_single_tensor_adamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[39m\n\u001b[32m    422\u001b[39m     device_beta1 = beta1\n\u001b[32m    424\u001b[39m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m \u001b[43mexp_avg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "traininng_loop(\n",
    "    model,\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    loss_fn = classification_loss,\n",
    "    optimizer = optimizer,\n",
    "    num_epochs = 10,\n",
    "    device = \"cpu\",\n",
    "    # text_to_generate = \"Every single step\",\n",
    "    look_back = config[\"context_window\"],\n",
    "    num_tokens_to_generate = config[\"num_tokens_to_generate\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 19:14:24,002 - INFO - Validation Loss: 6.3376\n"
     ]
    }
   ],
   "source": [
    "eval(\n",
    "    model,\n",
    "    val_loader=val_dl,\n",
    "    loss_fn= cross_entropy,\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
