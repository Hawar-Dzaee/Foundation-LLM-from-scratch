{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = 'The cat is hungry I went to the store But it was closed So I went to a different store'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the text into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.66\n",
    "split_index = int(len(raw_text) * ratio)\n",
    "train_raw_text = raw_text[:split_index]\n",
    "val_raw_text = raw_text[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train raw text:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The cat is hungry I went to the store But it was closed \n"
     ]
    }
   ],
   "source": [
    "print(\"Train raw text:\")\n",
    "print(\"-\"*100)\n",
    "print(train_raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val raw text:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "So I went to a different store\n"
     ]
    }
   ],
   "source": [
    "print(\"Val raw text:\")\n",
    "print(\"-\"*100)\n",
    "print(val_raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make an assumption that each word is a unique token.<br>\n",
    "This is a simplification and not true in the real world.<br>\n",
    "In practice, we would use a more sophisticated tokenization method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "The\n",
      "is\n",
      "So\n",
      "different\n",
      "went\n",
      "was\n",
      "store\n",
      "the\n",
      "closed\n",
      "But\n",
      "hungry\n",
      "cat\n",
      "to\n",
      "it\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(raw_text.split(' ')))\n",
    "\n",
    "for i in vocab:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 16\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f'vocab_size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of tokens to ids:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'The': 1,\n",
       " 'is': 2,\n",
       " 'So': 3,\n",
       " 'different': 4,\n",
       " 'went': 5,\n",
       " 'was': 6,\n",
       " 'store': 7,\n",
       " 'the': 8,\n",
       " 'closed': 9,\n",
       " 'But': 10,\n",
       " 'hungry': 11,\n",
       " 'cat': 12,\n",
       " 'to': 13,\n",
       " 'it': 14,\n",
       " 'I': 15}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_ids = {token: id for id, token in enumerate(vocab)}\n",
    "print(\"Mapping of tokens to ids:\")\n",
    "tokens_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of ids to tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'a',\n",
       " 1: 'The',\n",
       " 2: 'is',\n",
       " 3: 'So',\n",
       " 4: 'different',\n",
       " 5: 'went',\n",
       " 6: 'was',\n",
       " 7: 'store',\n",
       " 8: 'the',\n",
       " 9: 'closed',\n",
       " 10: 'But',\n",
       " 11: 'hungry',\n",
       " 12: 'cat',\n",
       " 13: 'to',\n",
       " 14: 'it',\n",
       " 15: 'I'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_tokens = {id: token for id, token in enumerate(vocab)}\n",
    "print(\"Mapping of ids to tokens:\")\n",
    "ids_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    return [tokens_to_ids[token] for token in text.strip().split(' ')]\n",
    "\n",
    "def decode(ids):\n",
    "    return ' '.join([ids_to_tokens[id] for id in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 12, 2, 11, 15, 5, 13, 8, 7, 10, 14, 6, 9, 3, 15, 5, 13, 0, 4, 7]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 12, 2, 11]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"The cat is hungry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'closed So was different'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([9,3,6,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,raw_text,max_len=4,stride=3):\n",
    "        self.token_ids = encode(raw_text)\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for i in range(0,len(self.token_ids)-max_len,stride):\n",
    "            input = self.token_ids[i:i+max_len]\n",
    "            output = self.token_ids[i+1:i+max_len+1]\n",
    "            self.X.append(torch.tensor(input))\n",
    "            self.y.append(torch.tensor(output))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 12,  2, 11]), tensor([12,  2, 11, 15]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Data(train_raw_text)\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3, 15,  5, 13]), tensor([15,  5, 13,  0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = Data(val_raw_text)\n",
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batch_size=1,shuffle=False,drop_last=False,num_workers=0)\n",
    "val_dl   = DataLoader(val_ds,batch_size=1,shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 1\n",
      "x :tensor([[ 1, 12,  2, 11]])\n",
      "y :tensor([[12,  2, 11, 15]])\n",
      "----------------------------------------\n",
      "Batch Number: 2\n",
      "x :tensor([[11, 15,  5, 13]])\n",
      "y :tensor([[15,  5, 13,  8]])\n",
      "----------------------------------------\n",
      "Batch Number: 3\n",
      "x :tensor([[13,  8,  7, 10]])\n",
      "y :tensor([[ 8,  7, 10, 14]])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(train_dl):\n",
    "  print(f'Batch Number: {i+1}')\n",
    "  print(f'x :{x}')\n",
    "  print(f'y :{y}')\n",
    "  print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 1\n",
      "x :tensor([[ 3, 15,  5, 13]])\n",
      "y :tensor([[15,  5, 13,  0]])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(val_dl):\n",
    "  print(f'Batch Number: {i+1}')\n",
    "  print(f'x :{x}')\n",
    "  print(f'y :{y}')\n",
    "  print('--'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking single batch, and we know that the batch size is 1. <br>\n",
    "so we are taking a single example from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 12,  2, 11]])\n",
      "tensor([[12,  2, 11, 15]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "  print(x)\n",
    "  print(y)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "B = 1  # batch size \n",
    "\n",
    "\n",
    "context_length = 4 # context window  [max length of the input sequence the model can handle]\n",
    "num_tokens = 4 # this can not be greater than context window\n",
    "d_in = 3  # embedding dimension \n",
    "d_out = 4 # output dimension \n",
    "\n",
    "dropout = 0.0 # notice that we are not using it, but we are still initializing it(to see how it works)\n",
    "\n",
    "num_heads = 2 \n",
    "head_dim = d_out//num_heads\n",
    "print(head_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Embedding  and Positional Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings:\n",
      "tensor([[[-1.6095, -0.1002, -0.6092],\n",
      "         [ 0.1991,  0.0457,  0.1530],\n",
      "         [-0.9798, -1.6091, -0.7121],\n",
      "         [-0.0721,  0.1578, -0.7735]]], grad_fn=<EmbeddingBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# Embedding \n",
    "token_emb = nn.Embedding(vocab_size,d_in)\n",
    "token_embedding = token_emb(x)\n",
    "print('Token Embeddings:')\n",
    "print(token_embedding)\n",
    "print('--'*20)\n",
    "print(token_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embeddings:\n",
      "----------------------------------------\n",
      "tensor([[ 0.6614,  0.2669,  0.0617],\n",
      "        [ 0.6213, -0.4519, -0.1661],\n",
      "        [-1.5228,  0.3817, -1.0276],\n",
      "        [-0.5631, -0.8923, -0.0583]], grad_fn=<EmbeddingBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# Positional embedding\n",
    "pos_emb = nn.Embedding(context_length,d_in)\n",
    "positional_embedding = pos_emb(torch.arange(num_tokens))\n",
    "print('Positional Embeddings:')\n",
    "print('--'*20)\n",
    "print(positional_embedding)\n",
    "print('--'*20)\n",
    "print(positional_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding + Positional Embedding\n",
      "----------------------------------------\n",
      "tensor([[[-0.9481,  0.1668, -0.5475],\n",
      "         [ 0.8204, -0.4062, -0.0132],\n",
      "         [-2.5025, -1.2274, -1.7398],\n",
      "         [-0.6352, -0.7345, -0.8317]]], grad_fn=<AddBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Token embedding + token embedding \n",
    "tok_pos_emb = token_embedding + positional_embedding\n",
    "print('Token Embedding + Positional Embedding')\n",
    "print('--'*20)\n",
    "print(tok_pos_emb)\n",
    "print('--'*20)\n",
    "print(tok_pos_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Transformer Block Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9481,  0.1668, -0.5475],\n",
       "         [ 0.8204, -0.4062, -0.0132],\n",
       "         [-2.5025, -1.2274, -1.7398],\n",
       "         [-0.6352, -0.7345, -0.8317]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "pre_transformer_dp = nn.Dropout(dropout)\n",
    "pre_transformer_dp_result = pre_transformer_dp(tok_pos_emb)\n",
    "pre_transformer_dp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0955,  1.3222, -0.2267],\n",
      "         [ 1.3428, -1.0556, -0.2871],\n",
      "         [-1.2966,  1.1373,  0.1593],\n",
      "         [ 1.2282, -0.0089, -1.2193]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "layernorm1 = nn.LayerNorm(d_in)\n",
    "layernorm1 = layernorm1(pre_transformer_dp_result)\n",
    "print(layernorm1)\n",
    "print('--'*20)\n",
    "print(layernorm1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_q\n",
      "tensor([[-0.2354,  0.2177, -0.4196,  0.2615],\n",
      "        [ 0.0191, -0.4919, -0.4590, -0.2133],\n",
      "        [-0.2867,  0.4232, -0.3648,  0.2161]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([3, 4])\n",
      "------------------------------------------------------------\n",
      "W_k\n",
      "tensor([[-0.4900, -0.1135, -0.1362,  0.1076],\n",
      "        [-0.3503, -0.4404,  0.1853,  0.1579],\n",
      "        [-0.2120,  0.3780,  0.4083,  0.5573]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([3, 4])\n",
      "------------------------------------------------------------\n",
      "W_v\n",
      "tensor([[-0.2604,  0.4126,  0.4929,  0.2377],\n",
      "        [ 0.1829,  0.4611,  0.2757,  0.4800],\n",
      "        [-0.2569, -0.5323,  0.2516, -0.0762]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "W_q = nn.Linear(d_in,d_out,bias=False)\n",
    "W_k = nn.Linear(d_in,d_out,bias=False)\n",
    "W_v = nn.Linear(d_in,d_out,bias=False)\n",
    "\n",
    "# REMINDER : THE WEIGHT MATRICES ARE TRANSPOSED \n",
    "print('W_q')\n",
    "print(W_q.weight.T)\n",
    "print(W_q.weight.T.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('W_k')\n",
    "print(W_k.weight.T)\n",
    "print(W_k.weight.T.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('W_v')\n",
    "print(W_v.weight.T)\n",
    "print(W_v.weight.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q,K,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      "tensor([[[ 0.3834, -0.5202,  0.5211, -0.4018],\n",
      "         [-0.1971,  0.3729, -0.1530,  0.2983],\n",
      "         [ 1.0646, -0.6774,  2.2483, -0.7684],\n",
      "         [ 0.3740, -0.1290,  0.9071, -0.1891]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n",
      "K\n",
      "tensor([[[ 0.5223, -0.1729, -0.0635, -0.3808],\n",
      "         [-0.2569,  0.0808, -0.1924,  0.0168],\n",
      "         [ 2.0250,  0.1668, -0.5970, -1.4325],\n",
      "         [ 0.7449,  0.0812, -0.3892, -0.6478]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n",
      "V\n",
      "tensor([[[ 4.1802e-01, -2.2869e-02, -5.5906e-01, -1.0358e-01],\n",
      "         [-2.8452e-01,  1.5820e-01,  2.8902e-01,  1.0334e-03],\n",
      "         [ 8.7407e-01, -6.7245e-01, -2.0095e+00, -1.0513e+00],\n",
      "         [ 2.4471e-01, -1.5805e-01, -7.2480e-01, -4.4010e-01]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "Q = W_q(tok_pos_emb)\n",
    "K = W_k(tok_pos_emb)\n",
    "V = W_v(tok_pos_emb)\n",
    "\n",
    "\n",
    "print(f'Q\\n{Q}')\n",
    "print(Q.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(f'K\\n{K}')\n",
    "print(K.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(f'V\\n{V}')\n",
    "print(V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting Q,K,V into multiple heads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3834, -0.5202],\n",
      "          [-0.1971,  0.3729],\n",
      "          [ 1.0646, -0.6774],\n",
      "          [ 0.3740, -0.1290]],\n",
      "\n",
      "         [[ 0.5211, -0.4018],\n",
      "          [-0.1530,  0.2983],\n",
      "          [ 2.2483, -0.7684],\n",
      "          [ 0.9071, -0.1891]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n",
      "------------------------------------------------------------\n",
      "tensor([[[[ 0.5223, -0.1729],\n",
      "          [-0.2569,  0.0808],\n",
      "          [ 2.0250,  0.1668],\n",
      "          [ 0.7449,  0.0812]],\n",
      "\n",
      "         [[-0.0635, -0.3808],\n",
      "          [-0.1924,  0.0168],\n",
      "          [-0.5970, -1.4325],\n",
      "          [-0.3892, -0.6478]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n",
      "------------------------------------------------------------\n",
      "tensor([[[[ 4.1802e-01, -2.2869e-02],\n",
      "          [-2.8452e-01,  1.5820e-01],\n",
      "          [ 8.7407e-01, -6.7245e-01],\n",
      "          [ 2.4471e-01, -1.5805e-01]],\n",
      "\n",
      "         [[-5.5906e-01, -1.0358e-01],\n",
      "          [ 2.8902e-01,  1.0334e-03],\n",
      "          [-2.0095e+00, -1.0513e+00],\n",
      "          [-7.2480e-01, -4.4010e-01]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "Q_split  = Q.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "K_split  = K.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "V_split  = V.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "\n",
    "\n",
    "print(Q_split)\n",
    "print(Q_split.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(K_split)\n",
    "print(K_split.shape)\n",
    "\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(V_split)\n",
    "print(V_split.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2901, -0.1406,  0.6896,  0.2434],\n",
       "          [-0.1674,  0.0808, -0.3370, -0.1166],\n",
       "          [ 0.6731, -0.3283,  2.0428,  0.7380],\n",
       "          [ 0.2176, -0.1065,  0.7358,  0.2681]],\n",
       "\n",
       "         [[ 0.1199, -0.1070,  0.2645,  0.0575],\n",
       "          [-0.1039,  0.0344, -0.3360, -0.1337],\n",
       "          [ 0.1498, -0.4454, -0.2415, -0.3773],\n",
       "          [ 0.0144, -0.1777, -0.2707, -0.2306]]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_score = Q_split @ K_split.transpose(2,3)\n",
    "attn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(num_tokens,num_tokens),diagonal=1)\n",
    "print(mask)\n",
    "print(mask.bool()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2901,    -inf,    -inf,    -inf],\n",
      "          [-0.1674,  0.0808,    -inf,    -inf],\n",
      "          [ 0.6731, -0.3283,  2.0428,    -inf],\n",
      "          [ 0.2176, -0.1065,  0.7358,  0.2681]],\n",
      "\n",
      "         [[ 0.1199,    -inf,    -inf,    -inf],\n",
      "          [-0.1039,  0.0344,    -inf,    -inf],\n",
      "          [ 0.1498, -0.4454, -0.2415,    -inf],\n",
      "          [ 0.0144, -0.1777, -0.2707, -0.2306]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_score = attn_score.masked_fill(mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
    "print(attn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4562, 0.5438, 0.0000, 0.0000],\n",
      "          [0.2423, 0.1194, 0.6383, 0.0000],\n",
      "          [0.2340, 0.1860, 0.3375, 0.2425]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4756, 0.5244, 0.0000, 0.0000],\n",
      "          [0.4141, 0.2719, 0.3140, 0.0000],\n",
      "          [0.2832, 0.2472, 0.2315, 0.2381]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weight = torch.softmax(attn_score/K_split.shape[-1]**0.5,dim=-1)\n",
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4562, 0.5438, 0.0000, 0.0000],\n",
      "          [0.2423, 0.1194, 0.6383, 0.0000],\n",
      "          [0.2340, 0.1860, 0.3375, 0.2425]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4756, 0.5244, 0.0000, 0.0000],\n",
      "          [0.4141, 0.2719, 0.3140, 0.0000],\n",
      "          [0.2832, 0.2472, 0.2315, 0.2381]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "\n",
    "attn_dropout = nn.Dropout(dropout)\n",
    "\n",
    "attn_weight = attn_dropout(attn_weight)\n",
    "print(attn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.4180, -0.0229],\n",
      "          [ 0.0360,  0.0756],\n",
      "          [ 0.6253, -0.4159],\n",
      "          [ 0.3992, -0.2412]],\n",
      "\n",
      "         [[-0.5591, -0.1036],\n",
      "          [-0.1143, -0.0487],\n",
      "          [-0.7840, -0.3727],\n",
      "          [-0.7246, -0.3772]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "con_vector = attn_weight @ V_split\n",
    "print(con_vector)\n",
    "print(con_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4180, -0.0229, -0.5591, -0.1036],\n",
       "         [ 0.0360,  0.0756, -0.1143, -0.0487],\n",
       "         [ 0.6253, -0.4159, -0.7840, -0.3727],\n",
       "         [ 0.3992, -0.2412, -0.7246, -0.3772]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_vector = con_vector.transpose(1,2).contiguous().view(B,num_tokens,d_out)\n",
    "conv_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4180, -0.0229, -0.5591, -0.1036],\n",
      "         [ 0.0360,  0.0756, -0.1143, -0.0487],\n",
      "         [ 0.6253, -0.4159, -0.7840, -0.3727],\n",
      "         [ 0.3992, -0.2412, -0.7246, -0.3772]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "dropout1 = nn.Dropout(dropout)\n",
    "after_dropout_1 = dropout1(conv_vector)\n",
    "print(after_dropout_1)\n",
    "print(after_dropout_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayerNorm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3988,  0.1269, -1.4198, -0.1059],\n",
      "         [ 0.6615,  1.1973, -1.3733, -0.4855],\n",
      "         [ 1.6491, -0.3425, -1.0466, -0.2600],\n",
      "         [ 1.5610, -0.0129, -1.2009, -0.3472]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "layernorm2 = nn.LayerNorm(after_dropout_1.shape[-1])\n",
    "layernorm2_result = layernorm2(after_dropout_1)\n",
    "\n",
    "print(layernorm2_result)\n",
    "print(layernorm2_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2576, -0.4707,  0.0695,  0.1826,  0.0725, -0.1862, -0.1602, -0.4888],\n",
      "        [-0.2207,  0.2999, -0.0612, -0.1949, -0.0020, -0.3020,  0.0239,  0.3100],\n",
      "        [-0.0969, -0.1029,  0.1387, -0.0365,  0.4371, -0.0838,  0.2981,  0.1397],\n",
      "        [ 0.2347,  0.2544,  0.0247, -0.0450,  0.1556, -0.2157,  0.2718,  0.4743]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "fc1 = nn.Linear(d_out,d_out*2)\n",
    "print(fc1.weight.T)\n",
    "print(fc1.weight.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7752, -0.9568, -0.5855,  0.0461, -0.0969, -0.2402, -0.4591,\n",
      "          -1.1252],\n",
      "         [ 0.2554, -0.3901, -0.7052, -0.2818, -0.1912, -0.3482, -0.4046,\n",
      "          -0.6066],\n",
      "         [ 0.8709, -1.2930, -0.4914,  0.1766,  0.0613, -0.1431, -0.4411,\n",
      "          -1.4141],\n",
      "         [ 0.7700, -1.1590, -0.5412,  0.1058, -0.0267, -0.1945, -0.4888,\n",
      "          -1.3318]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "fc1_result = fc1(layernorm2_result)\n",
    "print(fc1_result)\n",
    "print(fc1_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6053, -0.1620, -0.1634,  0.0239, -0.0447, -0.0973, -0.1483,\n",
       "          -0.1466],\n",
       "         [ 0.1534, -0.1359, -0.1695, -0.1096, -0.0811, -0.1267, -0.1387,\n",
       "          -0.1650],\n",
       "         [ 0.7038, -0.1267, -0.1531,  0.1007,  0.0322, -0.0634, -0.1454,\n",
       "          -0.1112],\n",
       "         [ 0.6001, -0.1428, -0.1592,  0.0574, -0.0131, -0.0823, -0.1527,\n",
       "          -0.1218]]], grad_fn=<GeluBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu = nn.GELU()\n",
    "gelu_result = gelu(fc1_result)\n",
    "gelu_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1822,  0.0491,  0.0512, -0.1133],\n",
      "        [-0.1561, -0.0433, -0.0014,  0.0169],\n",
      "        [-0.0685,  0.0981,  0.3091,  0.2108],\n",
      "        [ 0.1659,  0.0174,  0.1100,  0.1922],\n",
      "        [-0.3328,  0.1291, -0.1317, -0.3456],\n",
      "        [ 0.2120, -0.1378, -0.2135,  0.2192],\n",
      "        [-0.0727, -0.0258, -0.0593,  0.0988],\n",
      "        [ 0.1799, -0.0318, -0.1525,  0.3354]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "fc2 = nn.Linear(2*d_out,d_out)\n",
    "print(fc2.weight.T)\n",
    "print(fc2.weight.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3628, -0.2849, -0.2950, -0.3414],\n",
      "         [ 0.2565, -0.3114, -0.3214, -0.3158],\n",
      "         [ 0.3750, -0.2751, -0.3013, -0.3420],\n",
      "         [ 0.3615, -0.2836, -0.3012, -0.3329]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "fc2_result = fc2(gelu_result)\n",
    "print(fc2_result)\n",
    "print(fc2_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3628, -0.2849, -0.2950, -0.3414],\n",
       "         [ 0.2565, -0.3114, -0.3214, -0.3158],\n",
       "         [ 0.3750, -0.2751, -0.3013, -0.3420],\n",
       "         [ 0.3615, -0.2836, -0.3012, -0.3329]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "dropout2 = nn.Dropout(dropout)\n",
    "dropout2_result = dropout2(fc2_result)\n",
    "dropout2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Transformer block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Transformer Block LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.7273, -0.4994, -0.5342, -0.6937],\n",
      "         [ 1.7317, -0.5580, -0.5983, -0.5755],\n",
      "         [ 1.7263, -0.4707, -0.5590, -0.6967],\n",
      "         [ 1.7287, -0.4992, -0.5600, -0.6695]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "post_transformer_LN = nn.LayerNorm(d_out)\n",
    "post_transformer_LN_result = post_transformer_LN(dropout2_result)\n",
    "print(post_transformer_LN_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2576, -0.4707,  0.0695,  0.1826,  0.0725, -0.1862, -0.1602, -0.4888,\n",
      "          0.3300,  0.4391,  0.4906, -0.2634, -0.1444,  0.2713, -0.0234, -0.3232],\n",
      "        [-0.2207,  0.2999, -0.0612, -0.1949, -0.0020, -0.3020,  0.0239,  0.3100,\n",
      "         -0.4556, -0.0833, -0.2115,  0.2570, -0.0548, -0.1215, -0.3337,  0.3248],\n",
      "        [-0.0969, -0.1029,  0.1387, -0.0365,  0.4371, -0.0838,  0.2981,  0.1397,\n",
      "         -0.4754,  0.2140,  0.3750, -0.2654, -0.4807,  0.4980,  0.3045,  0.3036],\n",
      "        [ 0.2347,  0.2544,  0.0247, -0.0450,  0.1556, -0.2157,  0.2718,  0.4743,\n",
      "         -0.2412, -0.2324,  0.0059,  0.1471, -0.2384,  0.4008,  0.1552,  0.4434]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "torch.Size([4, 16])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[[ 0.1639, -1.1666,  0.0498,  0.5365, -0.5947, -0.3313, -0.3645,\n",
      "          -1.5199,  1.4631,  0.8754,  0.9128, -0.4336,  0.3820,  0.2331,\n",
      "          -0.6071, -0.9386],\n",
      "         [ 0.2119, -1.1496,  0.0477,  0.5457, -0.6039, -0.3345, -0.3535,\n",
      "          -1.4931,  1.4932,  0.8410,  0.9041, -0.4155,  0.3871,  0.2569,\n",
      "          -0.5889, -0.9261],\n",
      "         [ 0.1590, -1.1558,  0.0444,  0.5317, -0.6061, -0.3370, -0.3718,\n",
      "          -1.5154,  1.4621,  0.8679,  0.8970, -0.4198,  0.3931,  0.2158,\n",
      "          -0.6247, -0.9378],\n",
      "         [ 0.1724, -1.1585,  0.0469,  0.5365, -0.6021, -0.3346, -0.3658,\n",
      "          -1.5127,  1.4699,  0.8648,  0.9040, -0.4236,  0.3883,  0.2304,\n",
      "          -0.6113, -0.9361]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "head_out = nn.Linear(d_out,vocab_size)\n",
    "print(head_out.weight.T)\n",
    "print(head_out.weight.T.shape)\n",
    "\n",
    "print('----'*20)\n",
    "\n",
    "head_out_result = head_out(post_transformer_LN_result)\n",
    "print(head_out_result)\n",
    "print(head_out_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0590, 0.0156, 0.0527, 0.0857, 0.0276, 0.0360, 0.0348, 0.0110,\n",
       "          0.2164, 0.1203, 0.1248, 0.0325, 0.0734, 0.0633, 0.0273, 0.0196],\n",
       "         [0.0614, 0.0157, 0.0521, 0.0857, 0.0272, 0.0355, 0.0349, 0.0112,\n",
       "          0.2211, 0.1152, 0.1227, 0.0328, 0.0732, 0.0642, 0.0276, 0.0197],\n",
       "         [0.0590, 0.0159, 0.0526, 0.0857, 0.0275, 0.0359, 0.0347, 0.0111,\n",
       "          0.2173, 0.1199, 0.1235, 0.0331, 0.0746, 0.0625, 0.0270, 0.0197],\n",
       "         [0.0595, 0.0157, 0.0525, 0.0857, 0.0274, 0.0359, 0.0348, 0.0110,\n",
       "          0.2179, 0.1190, 0.1238, 0.0328, 0.0739, 0.0631, 0.0272, 0.0197]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we won't be using the following head_out_prob to calculate the loss, since we can use cross entropy loss \n",
    "# calculating softmax is for demonstration purpose only  \n",
    "\n",
    "head_out_prob = F.softmax(head_out_result,dim=-1)\n",
    "head_out_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 16])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 8, 8, 8]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out_result.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2260, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn(head_out_result.squeeze(0),y.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End of the forward pass "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
