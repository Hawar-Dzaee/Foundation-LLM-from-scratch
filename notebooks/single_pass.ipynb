{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = 'The cat is hungry I went to the store But it was closed So I went to a different store'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the text into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.66\n",
    "split_index = int(len(raw_text) * ratio)\n",
    "train_raw_text = raw_text[:split_index]\n",
    "val_raw_text = raw_text[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train raw text:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The cat is hungry I went to the store But it was closed \n"
     ]
    }
   ],
   "source": [
    "print(\"Train raw text:\")\n",
    "print(\"-\"*100)\n",
    "print(train_raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val raw text:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "So I went to a different store\n"
     ]
    }
   ],
   "source": [
    "print(\"Val raw text:\")\n",
    "print(\"-\"*100)\n",
    "print(val_raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make an assumption that each word is a unique token.<br>\n",
    "This is a simplification and not true in the real world.<br>\n",
    "In practice, we would use a more sophisticated tokenization method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But\n",
      "closed\n",
      "it\n",
      "cat\n",
      "hungry\n",
      "to\n",
      "is\n",
      "So\n",
      "different\n",
      "The\n",
      "I\n",
      "went\n",
      "the\n",
      "was\n",
      "store\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(raw_text.split(' ')))\n",
    "\n",
    "for i in vocab:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 16\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f'vocab_size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of tokens to ids:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'But': 0,\n",
       " 'closed': 1,\n",
       " 'it': 2,\n",
       " 'cat': 3,\n",
       " 'hungry': 4,\n",
       " 'to': 5,\n",
       " 'is': 6,\n",
       " 'So': 7,\n",
       " 'different': 8,\n",
       " 'The': 9,\n",
       " 'I': 10,\n",
       " 'went': 11,\n",
       " 'the': 12,\n",
       " 'was': 13,\n",
       " 'store': 14,\n",
       " 'a': 15}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_ids = {token: id for id, token in enumerate(vocab)}\n",
    "print(\"Mapping of tokens to ids:\")\n",
    "tokens_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of ids to tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'But',\n",
       " 1: 'closed',\n",
       " 2: 'it',\n",
       " 3: 'cat',\n",
       " 4: 'hungry',\n",
       " 5: 'to',\n",
       " 6: 'is',\n",
       " 7: 'So',\n",
       " 8: 'different',\n",
       " 9: 'The',\n",
       " 10: 'I',\n",
       " 11: 'went',\n",
       " 12: 'the',\n",
       " 13: 'was',\n",
       " 14: 'store',\n",
       " 15: 'a'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_tokens = {id: token for id, token in enumerate(vocab)}\n",
    "print(\"Mapping of ids to tokens:\")\n",
    "ids_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    return [tokens_to_ids[token] for token in text.strip().split(' ')]\n",
    "\n",
    "def decode(ids):\n",
    "    return ' '.join([ids_to_tokens[id] for id in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 3, 6, 4, 10, 11, 5, 12, 14, 0, 2, 13, 1, 7, 10, 11, 5, 15, 8, 14]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 3, 6, 4]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"The cat is hungry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat is hungry'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([9,3,6,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,raw_text,max_len=4,stride=3):\n",
    "        self.token_ids = encode(raw_text)\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for i in range(0,len(self.token_ids)-max_len,stride):\n",
    "            input = self.token_ids[i:i+max_len]\n",
    "            output = self.token_ids[i+1:i+max_len+1]\n",
    "            self.X.append(torch.tensor(input))\n",
    "            self.y.append(torch.tensor(output))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([9, 3, 6, 4]), tensor([ 3,  6,  4, 10]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Data(train_raw_text)\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 7, 10, 11,  5]), tensor([10, 11,  5, 15]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = Data(val_raw_text)\n",
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batch_size=1,shuffle=False,drop_last=False,num_workers=0)\n",
    "val_dl   = DataLoader(val_ds,batch_size=1,shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 1\n",
      "x :tensor([[9, 3, 6, 4]])\n",
      "y :tensor([[ 3,  6,  4, 10]])\n",
      "----------------------------------------\n",
      "Batch Number: 2\n",
      "x :tensor([[ 4, 10, 11,  5]])\n",
      "y :tensor([[10, 11,  5, 12]])\n",
      "----------------------------------------\n",
      "Batch Number: 3\n",
      "x :tensor([[ 5, 12, 14,  0]])\n",
      "y :tensor([[12, 14,  0,  2]])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(train_dl):\n",
    "  print(f'Batch Number: {i+1}')\n",
    "  print(f'x :{x}')\n",
    "  print(f'y :{y}')\n",
    "  print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 1\n",
      "x :tensor([[ 7, 10, 11,  5]])\n",
      "y :tensor([[10, 11,  5, 15]])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(val_dl):\n",
    "  print(f'Batch Number: {i+1}')\n",
    "  print(f'x :{x}')\n",
    "  print(f'y :{y}')\n",
    "  print('--'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking single batch, and we know that the batch size is 1. <br>\n",
    "so we are taking a single example from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 3, 6, 4]])\n",
      "tensor([[ 3,  6,  4, 10]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "  print(x)\n",
    "  print(y)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "B = 1  # batch size \n",
    "\n",
    "\n",
    "context_length = 4 # context window  [max length of the input sequence the model can handle]\n",
    "num_tokens = 4 # this can not be greater than context window\n",
    "d_in = 3  # embedding dimension \n",
    "d_out = 4 # output dimension \n",
    "\n",
    "dropout = 0.0 # notice that we are not using it, but we are still initializing it(to see how it works)\n",
    "\n",
    "num_heads = 2 \n",
    "head_dim = d_out//num_heads\n",
    "print(head_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Embedding  and Positional Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings:\n",
      "tensor([[[-1.4465,  0.0612, -0.6177],\n",
      "         [ 0.3037, -0.7773, -0.2515],\n",
      "         [ 0.6995,  0.1991,  0.8657],\n",
      "         [-0.2223,  1.6871,  0.2284]]], grad_fn=<EmbeddingBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# Embedding \n",
    "token_emb = nn.Embedding(vocab_size,d_in)\n",
    "token_embedding = token_emb(x)\n",
    "print('Token Embeddings:')\n",
    "print(token_embedding)\n",
    "print('--'*20)\n",
    "print(token_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embeddings:\n",
      "----------------------------------------\n",
      "tensor([[ 0.6614,  0.2669,  0.0617],\n",
      "        [ 0.6213, -0.4519, -0.1661],\n",
      "        [-1.5228,  0.3817, -1.0276],\n",
      "        [-0.5631, -0.8923, -0.0583]], grad_fn=<EmbeddingBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "# Positional embedding\n",
    "pos_emb = nn.Embedding(context_length,d_in)\n",
    "positional_embedding = pos_emb(torch.arange(num_tokens))\n",
    "print('Positional Embeddings:')\n",
    "print('--'*20)\n",
    "print(positional_embedding)\n",
    "print('--'*20)\n",
    "print(positional_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding + Positional Embedding\n",
      "----------------------------------------\n",
      "tensor([[[-0.7851,  0.3281, -0.5561],\n",
      "         [ 0.9250, -1.2292, -0.4176],\n",
      "         [-0.8232,  0.5808, -0.1619],\n",
      "         [-0.7853,  0.7948,  0.1702]]], grad_fn=<AddBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Token embedding + token embedding \n",
    "tok_pos_emb = token_embedding + positional_embedding\n",
    "print('Token Embedding + Positional Embedding')\n",
    "print('--'*20)\n",
    "print(tok_pos_emb)\n",
    "print('--'*20)\n",
    "print(tok_pos_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Transformer Block Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7851,  0.3281, -0.5561],\n",
       "         [ 0.9250, -1.2292, -0.4176],\n",
       "         [-0.8232,  0.5808, -0.1619],\n",
       "         [-0.7853,  0.7948,  0.1702]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "pre_transformer_dp = nn.Dropout(dropout)\n",
    "pre_transformer_dp_result = pre_transformer_dp(tok_pos_emb)\n",
    "pre_transformer_dp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9321,  1.3871, -0.4550],\n",
      "         [ 1.3121, -1.1129, -0.1992],\n",
      "         [-1.2004,  1.2477, -0.0473],\n",
      "         [-1.3007,  1.1310,  0.1697]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "----------------------------------------\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "layernorm1 = nn.LayerNorm(d_in)\n",
    "layernorm1 = layernorm1(pre_transformer_dp_result)\n",
    "print(layernorm1)\n",
    "print('--'*20)\n",
    "print(layernorm1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_q\n",
      "tensor([[-0.2354,  0.2177, -0.4196,  0.2615],\n",
      "        [ 0.0191, -0.4919, -0.4590, -0.2133],\n",
      "        [-0.2867,  0.4232, -0.3648,  0.2161]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([3, 4])\n",
      "------------------------------------------------------------\n",
      "W_k\n",
      "tensor([[-0.4900, -0.1135, -0.1362,  0.1076],\n",
      "        [-0.3503, -0.4404,  0.1853,  0.1579],\n",
      "        [-0.2120,  0.3780,  0.4083,  0.5573]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([3, 4])\n",
      "------------------------------------------------------------\n",
      "W_v\n",
      "tensor([[-0.2604,  0.4126,  0.4929,  0.2377],\n",
      "        [ 0.1829,  0.4611,  0.2757,  0.4800],\n",
      "        [-0.2569, -0.5323,  0.2516, -0.0762]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "W_q = nn.Linear(d_in,d_out,bias=False)\n",
    "W_k = nn.Linear(d_in,d_out,bias=False)\n",
    "W_v = nn.Linear(d_in,d_out,bias=False)\n",
    "\n",
    "# REMINDER : THE WEIGHT MATRICES ARE TRANSPOSED \n",
    "print('W_q')\n",
    "print(W_q.weight.T)\n",
    "print(W_q.weight.T.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('W_k')\n",
    "print(W_k.weight.T)\n",
    "print(W_k.weight.T.shape)\n",
    "print('---'*20)\n",
    "\n",
    "print('W_v')\n",
    "print(W_v.weight.T)\n",
    "print(W_v.weight.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q,K,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      "tensor([[[ 0.3506, -0.5677,  0.3817, -0.3954],\n",
      "         [-0.1215,  0.6294,  0.3284,  0.4139],\n",
      "         [ 0.2513, -0.5335,  0.1379, -0.3741],\n",
      "         [ 0.1513, -0.4900, -0.0974, -0.3381]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n",
      "K\n",
      "tensor([[[ 0.3877, -0.2656, -0.0593, -0.3425],\n",
      "         [ 0.0658,  0.2786, -0.5242, -0.3273],\n",
      "         [ 0.2343, -0.2236,  0.1536, -0.0871],\n",
      "         [ 0.0703, -0.1966,  0.3237,  0.1358]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n",
      "------------------------------------------------------------\n",
      "V\n",
      "tensor([[[ 0.4073,  0.1233, -0.4364,  0.0132],\n",
      "         [-0.3584,  0.0372,  0.0120, -0.3383],\n",
      "         [ 0.3622,  0.0143, -0.2864,  0.0954],\n",
      "         [ 0.3061, -0.0481, -0.1251,  0.1818]]], grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "Q = W_q(tok_pos_emb)\n",
    "K = W_k(tok_pos_emb)\n",
    "V = W_v(tok_pos_emb)\n",
    "\n",
    "\n",
    "print(f'Q\\n{Q}')\n",
    "print(Q.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(f'K\\n{K}')\n",
    "print(K.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(f'V\\n{V}')\n",
    "print(V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting Q,K,V into multiple heads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3506, -0.5677],\n",
      "          [-0.1215,  0.6294],\n",
      "          [ 0.2513, -0.5335],\n",
      "          [ 0.1513, -0.4900]],\n",
      "\n",
      "         [[ 0.3817, -0.3954],\n",
      "          [ 0.3284,  0.4139],\n",
      "          [ 0.1379, -0.3741],\n",
      "          [-0.0974, -0.3381]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n",
      "------------------------------------------------------------\n",
      "tensor([[[[ 0.3877, -0.2656],\n",
      "          [ 0.0658,  0.2786],\n",
      "          [ 0.2343, -0.2236],\n",
      "          [ 0.0703, -0.1966]],\n",
      "\n",
      "         [[-0.0593, -0.3425],\n",
      "          [-0.5242, -0.3273],\n",
      "          [ 0.1536, -0.0871],\n",
      "          [ 0.3237,  0.1358]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n",
      "------------------------------------------------------------\n",
      "tensor([[[[ 0.4073,  0.1233],\n",
      "          [-0.3584,  0.0372],\n",
      "          [ 0.3622,  0.0143],\n",
      "          [ 0.3061, -0.0481]],\n",
      "\n",
      "         [[-0.4364,  0.0132],\n",
      "          [ 0.0120, -0.3383],\n",
      "          [-0.2864,  0.0954],\n",
      "          [-0.1251,  0.1818]]]], grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "Q_split  = Q.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "K_split  = K.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "V_split  = V.view(B,num_tokens,num_heads,head_dim).transpose(1,2)\n",
    "\n",
    "\n",
    "print(Q_split)\n",
    "print(Q_split.shape)\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(K_split)\n",
    "print(K_split.shape)\n",
    "\n",
    "\n",
    "print('---'*20)\n",
    "\n",
    "print(V_split)\n",
    "print(V_split.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2867, -0.1351,  0.2091,  0.1363],\n",
       "          [-0.2143,  0.1673, -0.1692, -0.1323],\n",
       "          [ 0.2391, -0.1321,  0.1782,  0.1226],\n",
       "          [ 0.1888, -0.1265,  0.1450,  0.1070]],\n",
       "\n",
       "         [[ 0.1128, -0.0707,  0.0931,  0.0699],\n",
       "          [-0.1613, -0.3076,  0.0144,  0.1625],\n",
       "          [ 0.1200,  0.0501,  0.0538, -0.0062],\n",
       "          [ 0.1216,  0.1617,  0.0145, -0.0775]]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_score = Q_split @ K_split.transpose(2,3)\n",
    "attn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
